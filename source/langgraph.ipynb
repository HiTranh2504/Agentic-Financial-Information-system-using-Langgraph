{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start LangGraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_KEY\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import OpenAIEmbeddings\n",
    "# openai_embed_model = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import OpenAIEmbeddings\n",
    "# embed_model = OpenAIEmbeddings(model='text-embedding-3-small')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Dict, Any, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = None\n",
    "index = None\n",
    "embedding_model = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_store_and_retriever(resource_dir: str = \"sec_embeddings\") -> Tuple[List[Dict[str, Any]], faiss.Index, SentenceTransformer]:\n",
    "    global chunks, index, embedding_model\n",
    "    \n",
    "    if chunks is not None and index is not None and embedding_model is not None:\n",
    "        print(\"‚úÖ Vector store & retriever already initialized. Reusing...\")\n",
    "        return chunks, index, embedding_model\n",
    "\n",
    "    try:\n",
    "        print(f\"üìÅ Loading RAG vector store from: {resource_dir}\")\n",
    "        \n",
    "        with open(os.path.join(resource_dir, \"chunks.json\"), 'r', encoding='utf-8') as f:\n",
    "            chunks = json.load(f)\n",
    "        \n",
    "        with open(os.path.join(resource_dir, \"embeddings.pkl\"), 'rb') as f:\n",
    "            embeddings = pickle.load(f)\n",
    "        \n",
    "        index = faiss.read_index(os.path.join(resource_dir, \"faiss_index.bin\"))\n",
    "        embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "        \n",
    "        print(f\"‚úÖ Loaded {len(chunks)} chunks into memory.\")\n",
    "        print(\"‚úÖ FAISS index and SentenceTransformer initialized.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load vector store and retriever: {e}\")\n",
    "        chunks = None\n",
    "        index = None\n",
    "        embedding_model = None\n",
    "\n",
    "    return chunks, index, embedding_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Query Retrieval Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# T·∫°o LLM v·ªõi c·∫•u h√¨nh Pydantic V2\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# Parser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Prompt system\n",
    "SYS_PROMPT = \"\"\"\n",
    "You are an expert grader assessing whether a retrieved document contains relevant information to answer a user question.\n",
    "\n",
    "Please follow these rules:\n",
    "- Answer ONLY 'yes' or 'no'\n",
    "- If the document contains a numeric value, table, or sentence that directly answers the question (even partially), say 'yes'\n",
    "- Do NOT require exact match in wording; focus on meaning and key facts\n",
    "- Ignore formatting or markdown\n",
    "\n",
    "Be strict only when the document has no factual value for the question.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# T·∫°o prompt template\n",
    "grade_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", SYS_PROMPT),\n",
    "    (\"human\", \"Retrieved document:\\n{document}\\n\\nUser question:\\n{question}\")\n",
    "])\n",
    "\n",
    "# T·∫°o chain x·ª≠ l√Ω\n",
    "doc_grader = grade_prompt | llm | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a QA RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "\n",
    "# Create RAG prompt for response generation\n",
    "prompt = \"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If no context is present or if you don't know the answer, just say that you don't know the answer.\n",
    "Do not make up the answer unless it is there in the provided context.\n",
    "Give a detailed answer and to the point answer with regard to the question.\n",
    "Question:\n",
    "{question}\n",
    "Context:\n",
    "{context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(prompt)\n",
    "\n",
    "# Initialize connection with gpt-4.1-mini\n",
    "chatgpt = ChatOpenAI(model_name='gpt-4.1-mini', temperature=0)\n",
    "\n",
    "# Used for separating context docs with new lines\n",
    "def format_docs(docs):\n",
    "\treturn \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Create QA RAG chain\n",
    "qa_rag_chain = (\n",
    "\t{\n",
    "\t\t\"context\": (itemgetter('context')\n",
    "\t\t\t\t\t|\n",
    "\t\t\t\t\tRunnableLambda(format_docs)),\n",
    "\t\t\"question\": itemgetter('question')\n",
    "\t}\n",
    "\t|\n",
    "\tprompt_template\n",
    "\t|\n",
    "\tchatgpt\n",
    "\t|\n",
    "\tStrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Query Rephraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM for question rewriting\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "# Prompt template for rewriting\n",
    "SYS_PROMPT = \"\"\"Act as a question re-writer and perform the following task:\n",
    "\t\t\t\t - Convert the following input question to a better version that is optimized for web search.\n",
    "\t\t\t\t - When re-writing, look at the input question and try to reason about the underlying semantic intent / meaning.\n",
    "\t\t\t \"\"\"\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "\t[\n",
    "\t\t(\"system\", SYS_PROMPT),\n",
    "\t\t(\"human\", \"\"\"Here is the initial question:\n",
    "\t\t\t\t\t {question}\n",
    "\t\t\t\t\t Formulate an improved question.\n",
    "\t\t\t\t  \"\"\")\n",
    "\t]\n",
    ")\n",
    "\n",
    "# Create rephraser chain\n",
    "question_rewriter = (re_write_prompt|llm|StrOutputParser())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tv_search = TavilySearchResults(max_results=3, search_depth='advanced', max_tokens=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB Config: {'dbname': 'postgres', 'user': 'postgres.qgoljxbwnlmvrutlylwp', 'password': 'WrWOSApFIXB2kI7E', 'host': 'aws-0-ap-southeast-1.pooler.supabase.com', 'port': 6543, 'sslmode': 'require'}\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": os.getenv(\"DBNAME\") or os.getenv(\"POSTGRES_DB\"),\n",
    "    \"user\": os.getenv(\"DBUSER\") or os.getenv(\"POSTGRES_USER\"),\n",
    "    \"password\": os.getenv(\"DBPASSWORD\") or os.getenv(\"POSTGRES_PASSWORD\"),\n",
    "    \"host\": os.getenv(\"DBHOST\") or \"localhost\",\n",
    "    \"port\": int(os.getenv(\"DBPORT\", 5432)),\n",
    "    \"sslmode\": os.getenv(\"SSL_MODE\", \"require\")\n",
    "}\n",
    "\n",
    "\n",
    "print(f\"DB Config: {DB_CONFIG}\")\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def connect_to_database():\n",
    "    try:\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        print(\"K·∫øt n·ªëi th√†nh c√¥ng ƒë·∫øn PostgreSQL.\")\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"L·ªói k·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_schema_and_samples(conn):\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT table_name FROM information_schema.tables WHERE table_schema='public';\")\n",
    "        tables = cursor.fetchall()\n",
    "        schema_info = {}\n",
    "        for (table,) in tables:\n",
    "            cursor.execute(f\"SELECT column_name, data_type FROM information_schema.columns WHERE table_name = '{table}';\")\n",
    "            schema_info[table] = [{\"column_name\": col, \"data_type\": dtype} for col, dtype in cursor.fetchall()]\n",
    "            cursor.execute(f'SELECT * FROM \"{table}\" LIMIT 3;')\n",
    "            sample_rows = cursor.fetchall()\n",
    "            colnames = [desc[0] for desc in cursor.description]\n",
    "            schema_info[f\"{table}_samples\"] = [dict(zip(colnames, row)) for row in sample_rows]\n",
    "        cursor.close()\n",
    "        return schema_info\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def generate_sql_query(user_question, schema_info=None):\n",
    "    prompt = f\"\"\"\n",
    "You are a PostgreSQL expert. You are working with a financial database containing two structured tables: \"djia_prices\" and \"djia_companies\".\n",
    "\n",
    "IMPORTANT:\n",
    "- PostgreSQL is case-sensitive **only when using quoted identifiers**.\n",
    "- You MUST wrap column names in double quotes (e.g. \"Ticker\", \"Close\", \"Date\").\n",
    "- When comparing date values, always use `\"Date\"::date = 'YYYY-MM-DD'` to match correctly against date input.\n",
    "- NEVER use `\"Date\" = 'YYYY-MM-DD'` because \"Date\" is stored as TIMESTAMPTZ.\n",
    "\n",
    "Table 1: \"djia_prices\"\n",
    "{{\n",
    "\"Date\" (TIMESTAMPTZ),\n",
    "\"Open\" (FLOAT),\n",
    "\"High\" (FLOAT),\n",
    "\"Low\" (FLOAT),\n",
    "\"Close\" (FLOAT),\n",
    "\"Volume\" (BIGINT),\n",
    "\"Dividends\" (FLOAT),\n",
    "\"Stock_Splits\" (FLOAT),\n",
    "\"Ticker\" (VARCHAR)\n",
    "}}\n",
    "\n",
    "Table 2: \"djia_companies\"\n",
    "{{\n",
    "\"symbol\" (VARCHAR),\n",
    "\"name\" (TEXT),\n",
    "\"sector\" (TEXT),\n",
    "\"industry\" (TEXT),\n",
    "\"country\" (TEXT),\n",
    "\"market_cap\" (FLOAT),\n",
    "\"pe_ratio\" (FLOAT),\n",
    "\"dividend_yield\" (FLOAT),\n",
    "\"description\" (TEXT)\n",
    "}}\n",
    "\n",
    "Use this schema to write the most accurate and optimized PostgreSQL query to answer the following question.\n",
    "\n",
    "IMPORTANT:\n",
    "- DO NOT use subqueries on \"djia_companies\" to find the ticker by name.\n",
    "- Instead, directly use the stock symbol (e.g. 'BA', 'AAPL', 'MSFT') when querying djia_prices.\n",
    "- Assume the correct ticker will be matched externally by the system.\n",
    "\n",
    "IMPORTANT:\n",
    "- You MUST return only valid PostgreSQL SQL code.\n",
    "- DO NOT include explanation, comments, markdown, or Python code.\n",
    "- Return a single SQL query that can be executed directly.\n",
    "- Do not say \"this is a data science task\".\n",
    "- Assume the system will compute correlation and generate charts separately using Python.\n",
    "\n",
    "IMPORTANT:\n",
    "- Do NOT pivot data or return multiple tickers as columns.\n",
    "- Always return raw data in long-form: one row per Ticker per Date.\n",
    "- Required columns: \"Date\", \"Ticker\", \"Close\"\n",
    "- The system will compute correlation separately.\n",
    "\n",
    "\n",
    "Do NOT format the query in markdown. Return ONLY the raw SQL.\n",
    "\n",
    "- If the user asks for market capitalization by sector as of a specific date (e.g. April 26, 2025), you should just use the static table \"djia_companies\".\n",
    "- DO NOT use a subquery with \"djia_prices\" based on date.\n",
    "\n",
    "\n",
    "User Question:\n",
    "{user_question}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        sql_query = response.choices[0].message.content\n",
    "        sql_query = re.sub(r'^```sql', '', sql_query).strip('` \\n')\n",
    "        return sql_query\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói sinh SQL: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def execute_sql_query(conn, query):\n",
    "    try:\n",
    "        df = pd.read_sql(query, conn)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói th·ª±c thi SQL: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Agentic RAG components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search_needed: str\n",
    "    documents: List[str]\n",
    "documents: List[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve function for retrieval from Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "    print(\"---RETRIEVAL FROM VECTOR DB---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = []\n",
    "\n",
    "    chunks, index, model = get_vector_store_and_retriever(resource_dir=\"sec_embeddings\")\n",
    "\n",
    "    if index and chunks and model:\n",
    "        try:\n",
    "            # Encode query\n",
    "            query_embedding = model.encode([question])[0].reshape(1, -1).astype(np.float32)\n",
    "\n",
    "            # Search in the index\n",
    "            distances, indices = index.search(query_embedding, 3)\n",
    "            print(f\"üìå Retrieved top {len(indices[0])} docs from FAISS\")\n",
    "\n",
    "            for i, idx in enumerate(indices[0]):\n",
    "                if idx < len(chunks):\n",
    "                    chunk = chunks[idx]\n",
    "                    content = chunk[\"content\"]\n",
    "                    metadata = chunk.get(\"metadata\", {})\n",
    "                    score = float(1.0 / (1.0 + distances[0][i]))\n",
    "                    doc = Document(page_content=content, metadata=metadata)\n",
    "                    doc.metadata[\"score\"] = score\n",
    "                    documents.append(doc)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Retrieval error: {e}\")\n",
    "    else:\n",
    "        print(\"‚ùå No index/model/chunks available.\")\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grade documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state):\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state.get(\"documents\", [])\n",
    "\n",
    "    filtered_docs = []\n",
    "\n",
    "    if documents:\n",
    "        for d in documents:\n",
    "            # ‚úÖ N·∫øu t√†i li·ªáu l√† t·ª´ SQL ‚Üí lu√¥n cho qua\n",
    "            if d.metadata.get(\"source\") == \"sql\":\n",
    "                print(\"‚úÖ B·ªè qua grading (ngu·ªìn: SQL) ‚Üí gi·ªØ l·∫°i\")\n",
    "                filtered_docs.append(d)\n",
    "                continue\n",
    "\n",
    "            # C√≤n l·∫°i th√¨ d√πng LLM grading\n",
    "            score = doc_grader.invoke(\n",
    "                {\"question\": question, \"document\": d.page_content}\n",
    "            )\n",
    "            grade = score.strip().lower()\n",
    "\n",
    "            if grade == \"yes\":\n",
    "                print(\"‚úÖ GRADE: DOCUMENT RELEVANT\")\n",
    "                filtered_docs.append(d)\n",
    "            else:\n",
    "                print(\"‚ùå GRADE: DOCUMENT NOT RELEVANT\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Kh√¥ng c√≥ t√†i li·ªáu n√†o ƒë·ªÉ ch·∫•m ƒëi·ªÉm.\")\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"documents\": filtered_docs\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import get_close_matches\n",
    "\n",
    "DJIA_TICKERS = {\n",
    "    \"AAPL\", \"MSFT\", \"AMGN\", \"AXP\", \"BA\", \"CAT\", \"CRM\", \"CSCO\", \"CVX\", \"DIS\",\n",
    "    \"DOW\", \"GS\", \"HD\", \"HON\", \"IBM\", \"INTC\", \"JNJ\", \"JPM\", \"KO\", \"MCD\",\n",
    "    \"MMM\", \"MRK\", \"NKE\", \"PG\", \"TRV\", \"UNH\", \"V\", \"VZ\", \"WMT\"\n",
    "}\n",
    "\n",
    "\n",
    "def map_company_name_to_ticker(question: str, mapping: dict) -> str | None:\n",
    "    question_lower = question.lower()\n",
    "    \n",
    "    # T√¨m t√™n c√¥ng ty kh·ªõp g·∫ßn nh·∫•t\n",
    "    matched_names = get_close_matches(question_lower, mapping.keys(), n=1, cutoff=0.4)\n",
    "\n",
    "    if matched_names:\n",
    "        matched = matched_names[0]\n",
    "        print(f\"‚úÖ G·∫ßn ƒë√∫ng: '{matched}' ‚Üí {mapping[matched]}\")\n",
    "        return mapping[matched]\n",
    "\n",
    "    # N·∫øu kh√¥ng kh·ªõp fuzzy, fallback v·ªÅ in-string match\n",
    "    for name, ticker in mapping.items():\n",
    "        if name in question_lower:\n",
    "            print(f\"‚úÖ √Ånh x·∫° tr·ª±c ti·∫øp: '{name}' ‚Üí {ticker}\")\n",
    "            return ticker\n",
    "\n",
    "    print(\"‚ö†Ô∏è Kh√¥ng √°nh x·∫° ƒë∆∞·ª£c c√¥ng ty n√†o.\")\n",
    "    return None\n",
    "def get_name_to_ticker_mapping(conn):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('SELECT name, symbol FROM djia_companies')\n",
    "    result = cursor.fetchall()\n",
    "    cursor.close()\n",
    "\n",
    "    # Chu·∫©n h√≥a name v·ªÅ lowercase v√† b·ªè t·ª´ d∆∞ (Inc., Corp., Company,...)\n",
    "    clean_mapping = {}\n",
    "    for name, symbol in result:\n",
    "        name_clean = name.lower().replace(\"inc.\", \"\").replace(\"corporation\", \"\").replace(\"company\", \"\").replace(\"(the)\", \"\").strip()\n",
    "        clean_mapping[name_clean] = symbol\n",
    "\n",
    "    return clean_mapping\n",
    "\n",
    "def extract_tickers_from_question(question: str, conn=None) -> list:\n",
    "    question_upper = question.upper()\n",
    "\n",
    "    # ‚úÖ T√°ch c√¢u th√†nh c√°c t·ª´ vi·∫øt hoa (lo·∫°i b·ªè d·∫•u c√¢u)\n",
    "    tokens = set(re.findall(r'\\b[A-Z]{2,5}\\b', question_upper))\n",
    "\n",
    "    # ‚úÖ So kh·ªõp v·ªõi DJIA_TICKERS\n",
    "    tickers = [token for token in tokens if token in DJIA_TICKERS]\n",
    "\n",
    "    # ‚úÖ K·∫øt h·ª£p √°nh x·∫° t√™n c√¥ng ty n·∫øu c√≥ DB\n",
    "    if conn:\n",
    "        mapping = get_name_to_ticker_mapping(conn)\n",
    "        question_lower = question.lower()\n",
    "\n",
    "        matched_names = get_close_matches(question_lower, mapping.keys(), n=5, cutoff=0.4)\n",
    "        for name in matched_names:\n",
    "            ticker = mapping[name]\n",
    "            if ticker not in tickers:\n",
    "                tickers.append(ticker)\n",
    "\n",
    "        for name, ticker in mapping.items():\n",
    "            if name in question_lower and ticker not in tickers:\n",
    "                tickers.append(ticker)\n",
    "\n",
    "    print(f\"‚úÖ Ticker(s) detected: {tickers}\")\n",
    "    return tickers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K·∫øt n·ªëi th√†nh c√¥ng ƒë·∫øn PostgreSQL.\n",
      "‚úÖ Ticker(s) detected: ['MSFT', 'BA', 'JPM', 'WMT', 'AAPL']\n",
      "‚û°Ô∏è M√£ c·ªï phi·∫øu √°nh x·∫° ƒë∆∞·ª£c: ['MSFT', 'BA', 'JPM', 'WMT', 'AAPL']\n"
     ]
    }
   ],
   "source": [
    "question = \"Plot a heatmap of the correlation matrix of daily returns in 2024 for AAPL, MSFT, JPM, BA, and WMT\"\n",
    "# question = \"Create a boxplot of monthly closing prices of Walt Disney (DIS) for each month of 2024.\"\n",
    "# question = \"Create a boxplot of monthly closing prices of DIS for each month of 2024.\"\n",
    "\n",
    "conn = connect_to_database()\n",
    "if conn:\n",
    "    ticker = extract_tickers_from_question(question, conn)\n",
    "    print(f\"‚û°Ô∏è M√£ c·ªï phi·∫øu √°nh x·∫° ƒë∆∞·ª£c: {ticker}\")\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.schema import Document\n",
    "from finance_metrics import load_formulas, identify_metric, get_required_fields, compute_metric\n",
    "from plot_metric import plot_chart\n",
    "import re\n",
    "\n",
    "def extract_rolling_window(question: str, default: int = 30) -> int:\n",
    "    match = re.search(r\"(\\d+)[- ]day rolling average\", question.lower())\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return default\n",
    "\n",
    "\n",
    "def detect_chart_type(question: str):\n",
    "    q = question.lower()\n",
    "\n",
    "    if \"scatter\" in q or \"scatter plot\" in q:\n",
    "        return \"scatter\"\n",
    "    if \"bar chart\" in q or \"barplot\" in q or \"bar plot\" in q:\n",
    "        return \"bar\"\n",
    "    if \"pie chart\" in q or \"pie\" in q:\n",
    "        return \"pie\"\n",
    "    if \"boxplot\" in q or \"box plot\" in q:\n",
    "        return \"box\"\n",
    "    if \"histogram\" in q or \"hist\" in q:\n",
    "        return \"hist\"\n",
    "    if \"heatmap\" in q or \"correlation matrix\" in q:\n",
    "        return \"heatmap\"\n",
    "    if \"time series\" in q or \"plot the closing price\" in q or \"line chart\" in q or \"time-series\" in q:\n",
    "        return \"line\"\n",
    "    if \"rolling average\" in q or \"moving average\" in q:\n",
    "        return \"line_ma\"\n",
    "    if \"cumulative return\" in q:\n",
    "        return \"cumulative\"\n",
    "    if \"dividend\" in q:\n",
    "        return \"dividend\"\n",
    "    if \"high-low range\" in q or \"daily range\" in q:\n",
    "        return \"range\"\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def query_sql(state):\n",
    "    print(\"---EXECUTE RAW SQL QUERY OR METRIC COMPUTATION---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # B∆∞·ªõc 1: K·∫øt n·ªëi DB\n",
    "    conn = connect_to_database()\n",
    "    if conn is None:\n",
    "        raise ValueError(\"‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu.\")\n",
    "\n",
    "    # B∆∞·ªõc 2: Tr√≠ch xu·∫•t schema + sample ƒë·ªÉ ƒë∆∞a v√†o prompt LLM\n",
    "    schema_info = get_schema_and_samples(conn)\n",
    "\n",
    "    # B∆∞·ªõc 3: D√πng LLM sinh SQL truy v·∫•n\n",
    "    sql_query = generate_sql_query(question, schema_info)\n",
    "    if not sql_query:\n",
    "        conn.close()\n",
    "        raise ValueError(\"‚ùå Kh√¥ng th·ªÉ sinh truy v·∫•n SQL t·ª´ c√¢u h·ªèi.\")\n",
    "\n",
    "    print(f\"üß† Generated SQL Query:\\n{sql_query}\")\n",
    "\n",
    "    # B∆∞·ªõc 4: Th·ª±c thi SQL\n",
    "    df = execute_sql_query(conn, sql_query)\n",
    "    conn.close()\n",
    "\n",
    "    # B∆∞·ªõc 5: N·∫øu kh√¥ng c√≥ k·∫øt qu·∫£ ‚Üí fallback sang web\n",
    "    if df is None or df.empty:\n",
    "        print(\"‚ö†Ô∏è SQL tr·∫£ v·ªÅ r·ªóng. C·∫ßn d√πng web search.\")\n",
    "        return {\n",
    "            \"documents\": state[\"documents\"],\n",
    "            \"question\": question,\n",
    "            \"sql_query\": sql_query,\n",
    "            \"web_search_needed\": \"Yes\"\n",
    "        }\n",
    "\n",
    "    # B∆∞·ªõc 6: N·∫øu c√¢u h·ªèi y√™u c·∫ßu bi·ªÉu ƒë·ªì\n",
    "    chart_type = detect_chart_type(question)\n",
    "    if chart_type:\n",
    "        print(f\"üìä Detected chart type: {chart_type}\")\n",
    "\n",
    "        # Process separately for the heatmap chart\n",
    "        if chart_type == \"heatmap\":\n",
    "            print(\"üìä Detected heatmap request ‚Äî building correlation matrix.\")\n",
    "\n",
    "            conn = connect_to_database()\n",
    "            tickers = extract_tickers_from_question(question, conn)\n",
    "            if not tickers:\n",
    "                conn.close()\n",
    "                return {\n",
    "                    **state,\n",
    "                    \"generation\": \"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y m√£ c·ªï phi·∫øu trong c√¢u h·ªèi ƒë·ªÉ v·∫Ω heatmap.\"\n",
    "                }\n",
    "\n",
    "            tickers_str = \"', '\".join(tickers)\n",
    "            sql_query = f\"\"\"\n",
    "                SELECT \"Date\", \"Ticker\", \"Close\"\n",
    "                FROM \"djia_prices\"\n",
    "                WHERE \"Date\"::date BETWEEN '2024-01-01' AND '2024-12-31'\n",
    "                AND \"Ticker\" IN ('{tickers_str}')\n",
    "                ORDER BY \"Date\"\n",
    "            \"\"\"\n",
    "\n",
    "            print(f\"üß† SQL Query for heatmap:\\n{sql_query}\")\n",
    "            df = pd.read_sql(sql_query, conn)\n",
    "            conn.close()\n",
    "\n",
    "            if df.empty:\n",
    "                return {\n",
    "                    **state,\n",
    "                    \"generation\": \"‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu cho c√°c m√£ c·ªï phi·∫øu trong nƒÉm 2024.\"\n",
    "                }\n",
    "\n",
    "            # Chu·∫©n h√≥a returns theo t·ª´ng ticker\n",
    "            df[\"Date\"] = pd.to_datetime(df[\"Date\"], utc=True, errors=\"coerce\")\n",
    "            df = df.dropna(subset=[\"Date\", \"Close\", \"Ticker\"])\n",
    "\n",
    "            # Pivot: m·ªói ticker l√† 1 c·ªôt, m·ªói h√†ng l√† 1 ng√†y\n",
    "            pivot_df = df.pivot(index=\"Date\", columns=\"Ticker\", values=\"Close\")\n",
    "            returns_df = pivot_df.pct_change().dropna()\n",
    "\n",
    "            if returns_df.shape[1] < 2:\n",
    "                return {\n",
    "                    **state,\n",
    "                    \"generation\": \"‚ö†Ô∏è Kh√¥ng ƒë·ªß m√£ c·ªï phi·∫øu c√≥ d·ªØ li·ªáu ƒë·ªÉ t√≠nh t∆∞∆°ng quan.\"\n",
    "                }\n",
    "\n",
    "            # V·∫Ω heatmap t·ª´ returns\n",
    "            image_base64 = plot_chart(returns_df, \"heatmap\", question)\n",
    "\n",
    "            result_doc = Document(\n",
    "                page_content=\"üìä Correlation heatmap of daily returns generated below.\",\n",
    "                metadata={\"image_base64\": image_base64, \"source\": \"sql\"}\n",
    "            )\n",
    "\n",
    "            return {\n",
    "                \"documents\": state[\"documents\"] + [result_doc],\n",
    "                \"question\": question,\n",
    "                \"sql_query\": sql_query,\n",
    "                \"web_search_needed\": \"No\"\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        if chart_type == \"line_ma\":\n",
    "            window = extract_rolling_window(question)\n",
    "            ma_col = f\"MA_{window}\"\n",
    "            df[\"Date\"] = pd.to_datetime(df[\"Date\"], utc=True)\n",
    "            df[ma_col] = df[\"Close\"].rolling(window=window).mean()\n",
    "            df_chart = df[[\"Date\", \"Close\", ma_col]]\n",
    "\n",
    "            image_base64 = plot_chart(df_chart, chart_type, question)\n",
    "\n",
    "            result_doc = Document(\n",
    "                page_content=f\"üìä Chart generated: {chart_type}\",\n",
    "                metadata={\"image_base64\": image_base64, \"source\": \"sql\"}\n",
    "            )\n",
    "\n",
    "            return {\n",
    "                \"documents\": state[\"documents\"] + [result_doc],\n",
    "                \"question\": question,\n",
    "                \"sql_query\": sql_query,\n",
    "                \"web_search_needed\": \"No\"\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "        if df is not None and not df.empty:\n",
    "            df[\"Date\"] = pd.to_datetime(df[\"Date\"], utc=True, errors=\"coerce\")\n",
    "            df = df.dropna(subset=[\"Date\"])\n",
    "            \n",
    "            image_base64 = plot_chart(df, chart_type, question)\n",
    "\n",
    "            if image_base64:\n",
    "                result_doc = Document(\n",
    "                    page_content=f\"üìä The requested chart has been generated below.\",\n",
    "                    metadata={\"image_base64\": image_base64, \"source\": \"sql\"}\n",
    "                )\n",
    "            else:\n",
    "                result_doc = Document(\n",
    "                    page_content=f\"‚ö†Ô∏è Failed to generate chart.\",\n",
    "                    metadata={\"source\": \"sql\"}\n",
    "                )\n",
    "            return {\n",
    "                \"documents\": state[\"documents\"] + [result_doc],\n",
    "                \"question\": question,\n",
    "                \"sql_query\": sql_query,\n",
    "                \"web_search_needed\": \"No\"\n",
    "            }\n",
    "        else:\n",
    "            result_doc = Document(\n",
    "                page_content=\"‚ö†Ô∏è No data available for charting.\",\n",
    "                metadata={\"source\": \"sql\"}\n",
    "            )\n",
    "\n",
    "    else:\n",
    "        # N·∫øu kh√¥ng ph·∫£i c√¢u h·ªèi y√™u c·∫ßu bi·ªÉu ƒë·ªì ‚Üí tr·∫£ k·∫øt qu·∫£ d·∫°ng b·∫£ng\n",
    "        result_doc = Document(\n",
    "            page_content=f\"üìä SQL Query Result:\\n\\n{df.to_markdown(index=False)}\",\n",
    "            metadata={\"source\": \"sql\"}\n",
    "        )\n",
    "\n",
    "    # Tr·∫£ k·∫øt qu·∫£ v·ªÅ state\n",
    "    return {\n",
    "        \"documents\": state[\"documents\"] + [result_doc],\n",
    "        \"question\": question,\n",
    "        \"sql_query\": sql_query,\n",
    "        \"web_search_needed\": \"No\"\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess combined documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_combined_documents(state):\n",
    "    print(\"---REASSESS COMBINED DOCUMENTS---\")\n",
    "\n",
    "    question = state.get(\"question\", \"\")\n",
    "    all_docs = state.get(\"documents\", [])\n",
    "\n",
    "    reassessed_docs = []\n",
    "\n",
    "    for doc in all_docs:\n",
    "        score = doc_grader.invoke({\"question\": question, \"document\": doc.page_content}).strip().lower()\n",
    "        if score == \"yes\":\n",
    "            print(\"‚úÖ Reassessed: Relevant\")\n",
    "            reassessed_docs.append(doc)\n",
    "        else:\n",
    "            print(\"‚ùå Reassessed: Not relevant\")\n",
    "\n",
    "    print(f\"üîç Number of relevant documents after reassessment: {len(reassessed_docs)}\")\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"documents\": reassessed_docs\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decide after reassessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_after_reassessment(state):\n",
    "    docs = state.get(\"documents\", [])\n",
    "    num_docs = len(docs)\n",
    "    print(f\"üîç Number of relevant documents after reassessment: {num_docs}\")\n",
    "\n",
    "    if num_docs >= 1:\n",
    "        print(\"‚úÖ Enough relevant documents found ‚Üí proceed to generate_answer\")\n",
    "        return \"generate_answer\"\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Not enough relevant documents ‚Üí fallback to rewrite_query\")\n",
    "        return \"rewrite_query\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rewrite query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_query(state):\n",
    "    print(\"---REWRITE QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    # Re-write question\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"documents\": documents, \"question\": better_question}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decide web search or generate answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_after_sql(state):\n",
    "    if state.get(\"web_search_needed\", \"No\") == \"Yes\":\n",
    "        print(\"---DECISION: Missing SQL data ‚Üí web search---\")\n",
    "        return \"rewrite_query\"\n",
    "    \n",
    "    print(\"---DECISION: Sufficient SQL data ‚Üí generate answer---\")\n",
    "    return \"generate_answer\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document  # d√πng ƒë√∫ng version core\n",
    "\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Perform web search based on the rewritten question and return a unified Document.\n",
    "    \"\"\"\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state.get(\"documents\", [])\n",
    "\n",
    "    try:\n",
    "        docs = tv_search.invoke(question)\n",
    "\n",
    "        if not docs:\n",
    "            print(\"‚ö†Ô∏è No results returned from web search.\")\n",
    "            return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "        print(\"üì• Web search results received.\")\n",
    "        print(\"DOCS TYPE:\", type(docs))\n",
    "        print(\"FIRST ELEMENT TYPE:\", type(docs[0]) if docs else \"EMPTY\")\n",
    "\n",
    "        # Format content\n",
    "        if isinstance(docs[0], str):\n",
    "            web_content = \"\\n\\n\".join(docs)\n",
    "        elif isinstance(docs[0], dict) and \"content\" in docs[0]:\n",
    "            web_content = \"\\n\\n\".join([d[\"content\"] for d in docs])\n",
    "        elif isinstance(docs[0], Document):\n",
    "            web_content = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported document format: {type(docs[0])}\")\n",
    "\n",
    "        # Append web search result as 1 Document\n",
    "        web_results = Document(\n",
    "            page_content=web_content,\n",
    "            metadata={\"source\": \"web_search\"}\n",
    "        )\n",
    "\n",
    "        documents.append(web_results)\n",
    "        print(\"‚úÖ Web search content appended to documents.\")\n",
    "        return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during web search: {str(e)}\")\n",
    "        return {\"documents\": documents, \"question\": question}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state):\n",
    "    print(\"---GENERATE ANSWER---\")\n",
    "\n",
    "    question = state.get(\"question\", \"\")\n",
    "    documents = state.get(\"documents\", [])\n",
    "\n",
    "    if not question:\n",
    "        print(\"‚ö†Ô∏è No question provided.\")\n",
    "        return {**state, \"generation\": \"No question was given.\"}\n",
    "\n",
    "    if not documents:\n",
    "        print(\"‚ö†Ô∏è No documents available for context.\")\n",
    "        return {**state, \"generation\": \"I don't have enough context to answer the question.\"}\n",
    "\n",
    "    try:\n",
    "        # ‚úÖ N·∫øu c√≥ t√†i li·ªáu ch·ª©a ·∫£nh (image_base64) ‚Üí hi·ªÉn th·ªã ngay, kh√¥ng g·ªçi LLM\n",
    "        for doc in documents:\n",
    "            if isinstance(doc, Document) and doc.metadata.get(\"image_base64\"):\n",
    "                print(\"‚úÖ Found image in document ‚Üí skipping LLM\")\n",
    "                return {\n",
    "                    **state,\n",
    "                    \"generation\": \"üìä The requested chart has been generated below.\",\n",
    "                    \"image_base64\": doc.metadata[\"image_base64\"]\n",
    "                }\n",
    "\n",
    "        # ‚ùó N·∫øu kh√¥ng c√≥ ·∫£nh ‚Üí fallback sang LLM\n",
    "        generation = qa_rag_chain.invoke({\n",
    "            \"context\": documents,\n",
    "            \"question\": question\n",
    "        })\n",
    "\n",
    "        print(\"‚úÖ Answer generated from LLM.\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"generation\": generation\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during answer generation: {str(e)}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"generation\": f\"Error generating answer: {str(e)}\"\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Agent Graph with LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# === Build Agentic RAG: vector ‚Üí SQL ‚Üí (chart or reassess) ‚Üí answer/web ===\n",
    "agentic_rag = StateGraph(GraphState)\n",
    "\n",
    "# Add nodes\n",
    "agentic_rag.add_node(\"retrieve\", retrieve)\n",
    "agentic_rag.add_node(\"grade_documents\", grade_documents)\n",
    "agentic_rag.add_node(\"query_sql\", query_sql)\n",
    "agentic_rag.add_node(\"assess_combined_documents\", assess_combined_documents)\n",
    "agentic_rag.add_node(\"rewrite_query\", rewrite_query)\n",
    "agentic_rag.add_node(\"web_search\", web_search)\n",
    "agentic_rag.add_node(\"generate_answer\", generate_answer)\n",
    "\n",
    "# Entry point\n",
    "agentic_rag.set_entry_point(\"retrieve\")\n",
    "\n",
    "# Flow: retrieve ‚Üí grade_documents\n",
    "agentic_rag.add_edge(\"retrieve\", \"grade_documents\")\n",
    "\n",
    "# N·∫øu c√≥ docs ‚Üí generate_answer, n·∫øu kh√¥ng ‚Üí query_sql\n",
    "agentic_rag.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    lambda state: \"generate_answer\" if len(state.get(\"documents\", [])) >= 1 else \"query_sql\",\n",
    "    {\n",
    "        \"generate_answer\": \"generate_answer\",\n",
    "        \"query_sql\": \"query_sql\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# ‚úÖ THAY ƒê·ªîI ·ªû ƒê√ÇY: ph√¢n nh√°nh sau query_sql d·ª±a tr√™n bi·ªÉu ƒë·ªì/web search\n",
    "def decide_after_query_sql(state):\n",
    "    question = state.get(\"question\", \"\")\n",
    "    if detect_chart_type(question):\n",
    "        print(\"---DECISION: This is a charting question ‚Üí generate_answer\")\n",
    "        return \"generate_answer\"\n",
    "    elif state.get(\"web_search_needed\", \"No\") == \"Yes\":\n",
    "        print(\"---DECISION: SQL failed ‚Üí fallback to rewrite_query\")\n",
    "        return \"rewrite_query\"\n",
    "    else:\n",
    "        print(\"---DECISION: Proceed to reassess documents\")\n",
    "        return \"assess_combined_documents\"\n",
    "\n",
    "agentic_rag.add_conditional_edges(\n",
    "    \"query_sql\",\n",
    "    decide_after_query_sql,\n",
    "    {\n",
    "        \"generate_answer\": \"generate_answer\",\n",
    "        \"rewrite_query\": \"rewrite_query\",\n",
    "        \"assess_combined_documents\": \"assess_combined_documents\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Flow ti·∫øp theo t·ª´ reassess\n",
    "agentic_rag.add_conditional_edges(\n",
    "    \"assess_combined_documents\",\n",
    "    decide_after_reassessment,  # return \"generate_answer\" or \"rewrite_query\"\n",
    "    {\n",
    "        \"generate_answer\": \"generate_answer\",\n",
    "        \"rewrite_query\": \"rewrite_query\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Web search ‚Üí generate answer\n",
    "agentic_rag.add_edge(\"rewrite_query\", \"web_search\")\n",
    "agentic_rag.add_edge(\"web_search\", \"generate_answer\")\n",
    "\n",
    "# End\n",
    "agentic_rag.add_edge(\"generate_answer\", END)\n",
    "\n",
    "# Compile\n",
    "agentic_rag = agentic_rag.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langgraph.graph.state.CompiledStateGraph'>\n"
     ]
    }
   ],
   "source": [
    "print(type(agentic_rag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display, Markdown\n",
    "# display(Image(agentic_rag.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Agentic RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from IPython.display import Image as IPImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import base64\n",
    "\n",
    "def show_result(response):\n",
    "    display(Markdown(response.get(\"generation\", \"\")))\n",
    "    for doc in response.get(\"documents\", []):\n",
    "        if isinstance(doc, Document) and \"image_base64\" in doc.metadata:\n",
    "            img_data = base64.b64decode(doc.metadata[\"image_base64\"])\n",
    "            display(IPImage(data=img_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"What was the highest price Apple reached on February 28, 2025?\"\n",
    "# response = agentic_rag.invoke({\"question\": query})\n",
    "# display(Markdown(response['generation']))\n",
    "# show_result(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"Plot the time series of Microsoft (MSFT) stock closing price from June 1, 2024 to September 30, 2024.\"\n",
    "# response = agentic_rag.invoke({\"question\": query})\n",
    "# display(Markdown(response['generation']))\n",
    "# show_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"What was the opening price of Boeing on August 1, 2023?\"\n",
    "# response = agentic_rag.invoke({\"question\": query})\n",
    "# display(Markdown(response['generation']))\n",
    "# show_result(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"Create a bar chart of Caterpillar (CAT) average monthly closing price in 2024\"\n",
    "# response = agentic_rag.invoke({\"question\": query})\n",
    "# display(Markdown(response['generation']))\n",
    "# show_result(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"Create a pie chart of market capitalization proportions by sector as of April 26, 2025\"\n",
    "# response = agentic_rag.invoke({\"question\": query})\n",
    "# display(Markdown(response['generation']))\n",
    "# show_result(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVAL FROM VECTOR DB---\n",
      "üìÅ Loading RAG vector store from: sec_embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 89 chunks into memory.\n",
      "‚úÖ FAISS index and SentenceTransformer initialized.\n",
      "üìå Retrieved top 3 docs from FAISS\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "‚ùå GRADE: DOCUMENT NOT RELEVANT\n",
      "‚ùå GRADE: DOCUMENT NOT RELEVANT\n",
      "‚ùå GRADE: DOCUMENT NOT RELEVANT\n",
      "---EXECUTE RAW SQL QUERY OR METRIC COMPUTATION---\n",
      "K·∫øt n·ªëi th√†nh c√¥ng ƒë·∫øn PostgreSQL.\n",
      "üß† Generated SQL Query:\n",
      "SELECT \n",
      "    \"Date\", \n",
      "    \"Ticker\", \n",
      "    (\"Close\" - LAG(\"Close\", 1) OVER (ORDER BY \"Date\")) / LAG(\"Close\", 1) OVER (ORDER BY \"Date\") AS \"Daily_Return\"\n",
      "FROM \n",
      "    \"djia_prices\"\n",
      "WHERE \n",
      "    \"Ticker\" = 'AAPL' AND\n",
      "    \"Date\"::date >= '2024-01-01' AND \n",
      "    \"Date\"::date <= '2024-12-31'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trung\\AppData\\Local\\Temp\\ipykernel_20452\\3623657544.py:127: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Detected chart type: box\n",
      "---DECISION: This is a charting question ‚Üí generate_answer\n",
      "---GENERATE ANSWER---\n",
      "‚úÖ Found image in document ‚Üí skipping LLM\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "üìä The requested chart has been generated below."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "üìä The requested chart has been generated below."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Create a boxplot of daily returns for Apple (AAPL) in 2024.\"\n",
    "response = agentic_rag.invoke({\"question\": query})\n",
    "display(Markdown(response['generation']))\n",
    "show_result(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"Plot the cumulative return of UnitedHealth Group (UNH) during 2024.\"\n",
    "# response = agentic_rag.invoke({\"question\": query})\n",
    "# display(Markdown(response['generation']))\n",
    "# show_result(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \" Plot a heatmap of the correlation matrix of daily returns in 2024 for AAPL, MSFT, JPM, BA, and WMT.\"\n",
    "# response = agentic_rag.invoke({\"question\": query})\n",
    "# display(Markdown(response['generation']))\n",
    "# show_result(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"Plot Microsoft (MSFT) daily closing price and its 30-day rolling average during 2024\"\n",
    "# response = agentic_rag.invoke({\"question\": query})\n",
    "# display(Markdown(response['generation']))\n",
    "# show_result(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
