{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start LangGraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain==0.2.0\n",
    "# !pip install langchain-openai==0.1.7\n",
    "# !pip install langchain-community==0.2.0\n",
    "# !pip install langgraph==0.1.1\n",
    "# !pip install langchain-chroma==0.1.1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use file .env to get the API key\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_KEY\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "openai_embed_model = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "import pandas as pd\n",
    "\n",
    "companies_df = pd.read_csv(\"Data Kien/djia_companies_20250426.csv\")\n",
    "companies_df.head()\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=row['description'],\n",
    "        metadata={'symbol': row['symbol'], 'name': row['name'], 'sector': row['sector']}\n",
    "    )\n",
    "    for _, row in companies_df.iterrows()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "chunked_docs = splitter.split_documents(docs)\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embed_model = OpenAIEmbeddings(model='text-embedding-3-small')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "chroma_db = Chroma.from_documents(\n",
    "    documents=chunked_docs,\n",
    "    embedding=embed_model,\n",
    "    collection_name='djia_company_info',\n",
    "    persist_directory=\"./djia_vector_db\"\n",
    ")\n",
    "similarity_threshold_retriever  = chroma_db.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"k\": 3, \"score_threshold\": 0.3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Inc. -> Apple Inc. designs, manufactures, and markets smartphones, personal computers, tablets, wearables, and accessories worldwide. The company offers iPhone, a line of smartphones; Mac, a line of personal \n",
      "Apple Inc. -> Apple Inc. designs, manufactures, and markets smartphones, personal computers, tablets, wearables, and accessories worldwide. The company offers iPhone, a line of smartphones; Mac, a line of personal \n",
      "Apple Inc. -> Apple Inc. designs, manufactures, and markets smartphones, personal computers, tablets, wearables, and accessories worldwide. The company offers iPhone, a line of smartphones; Mac, a line of personal \n"
     ]
    }
   ],
   "source": [
    "query = \"What does Apple do?\"\n",
    "results = similarity_threshold_retriever .invoke(query)\n",
    "for r in results:\n",
    "    print(r.metadata['name'], \"->\", r.page_content[:200])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Query Retrieval Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# T·∫°o LLM v·ªõi c·∫•u h√¨nh Pydantic V2\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# Parser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Prompt system\n",
    "SYS_PROMPT = \"\"\"\n",
    "You are an expert grader assessing relevance of a retrieved document to a user question.\n",
    "Answer only 'yes' or 'no' depending on whether the document is relevant to the question.\n",
    "\"\"\"\n",
    "\n",
    "# T·∫°o prompt template\n",
    "grade_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", SYS_PROMPT),\n",
    "    (\"human\", \"Retrieved document:\\n{document}\\n\\nUser question:\\n{question}\")\n",
    "])\n",
    "\n",
    "# T·∫°o chain x·ª≠ l√Ω\n",
    "doc_grader = grade_prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Inc. designs, manufactures, and markets smartphones, personal computers, tablets, wearables, and accessories worldwide. The company offers iPhone, a line of smartphones; Mac, a line of personal computers; iPad, a line of multi-purpose tablets; and wearables, home, and accessories comprising AirPods, Apple TV, Apple Watch, Beats products, and HomePod. It also provides AppleCare support and cloud services; and operates various platforms, including the App Store that allow customers to discover and download applications and digital content, such as books, music, video, games, and podcasts, as well as advertising services include third-party licensing arrangements and its own advertising platforms. In addition, the company offers various subscription-based services, such as Apple Arcade, a game subscription service; Apple Fitness+, a personalized fitness service; Apple Music, which offers users a curated listening experience with on-demand radio stations; Apple News+, a subscription\n",
      "GRADE: yes\n",
      "\n",
      "Apple Inc. designs, manufactures, and markets smartphones, personal computers, tablets, wearables, and accessories worldwide. The company offers iPhone, a line of smartphones; Mac, a line of personal computers; iPad, a line of multi-purpose tablets; and wearables, home, and accessories comprising AirPods, Apple TV, Apple Watch, Beats products, and HomePod. It also provides AppleCare support and cloud services; and operates various platforms, including the App Store that allow customers to discover and download applications and digital content, such as books, music, video, games, and podcasts, as well as advertising services include third-party licensing arrangements and its own advertising platforms. In addition, the company offers various subscription-based services, such as Apple Arcade, a game subscription service; Apple Fitness+, a personalized fitness service; Apple Music, which offers users a curated listening experience with on-demand radio stations; Apple News+, a subscription\n",
      "GRADE: yes\n",
      "\n",
      "Apple Inc. designs, manufactures, and markets smartphones, personal computers, tablets, wearables, and accessories worldwide. The company offers iPhone, a line of smartphones; Mac, a line of personal computers; iPad, a line of multi-purpose tablets; and wearables, home, and accessories comprising AirPods, Apple TV, Apple Watch, Beats products, and HomePod. It also provides AppleCare support and cloud services; and operates various platforms, including the App Store that allow customers to discover and download applications and digital content, such as books, music, video, games, and podcasts, as well as advertising services include third-party licensing arrangements and its own advertising platforms. In addition, the company offers various subscription-based services, such as Apple Arcade, a game subscription service; Apple Fitness+, a personalized fitness service; Apple Music, which offers users a curated listening experience with on-demand radio stations; Apple News+, a subscription\n",
      "GRADE: yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What does Apple do?\"\n",
    "top3_docs = similarity_threshold_retriever.invoke(query)\n",
    "for doc in top3_docs:\n",
    "\tprint(doc.page_content)\n",
    "\tprint('GRADE:', doc_grader.invoke({\n",
    "\t\t\"question\": query,\n",
    "\t\t\"document\": doc.page_content\n",
    "\t}))\n",
    "\tprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a QA RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "\n",
    "# Create RAG prompt for response generation\n",
    "prompt = \"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If no context is present or if you don't know the answer, just say that you don't know the answer.\n",
    "Do not make up the answer unless it is there in the provided context.\n",
    "Give a detailed answer and to the point answer with regard to the question.\n",
    "Question:\n",
    "{question}\n",
    "Context:\n",
    "{context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(prompt)\n",
    "\n",
    "# Initialize connection with gpt-4.1-mini\n",
    "chatgpt = ChatOpenAI(model_name='gpt-4.1-mini', temperature=0)\n",
    "\n",
    "# Used for separating context docs with new lines\n",
    "def format_docs(docs):\n",
    "\treturn \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Create QA RAG chain\n",
    "qa_rag_chain = (\n",
    "\t{\n",
    "\t\t\"context\": (itemgetter('context')\n",
    "\t\t\t\t\t|\n",
    "\t\t\t\t\tRunnableLambda(format_docs)),\n",
    "\t\t\"question\": itemgetter('question')\n",
    "\t}\n",
    "\t|\n",
    "\tprompt_template\n",
    "\t|\n",
    "\tchatgpt\n",
    "\t|\n",
    "\tStrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Inc. designs, manufactures, and markets a wide range of technology products and services worldwide. Its product lineup includes smartphones (iPhone), personal computers (Mac), multi-purpose tablets (iPad), and various wearables and accessories such as AirPods, Apple TV, Apple Watch, Beats products, and HomePod. Beyond hardware, Apple provides support services like AppleCare and cloud services. The company also operates digital platforms, including the App Store, which enables customers to discover and download applications and digital content such as books, music, videos, games, and podcasts. Additionally, Apple offers advertising services through third-party licensing and its own advertising platforms. It also provides several subscription-based services, including Apple Arcade (a game subscription service), Apple Fitness+ (a personalized fitness service), Apple Music (a curated music streaming service), and Apple News+ (a subscription news service).\n"
     ]
    }
   ],
   "source": [
    "query = \"What does Apple do?\"\n",
    "top3_docs = similarity_threshold_retriever.invoke(query)\n",
    "result = qa_rag_chain.invoke({\"context\": top3_docs, \"question\": query})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\vectorstores\\base.py:1045: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'name': 'Coca-Cola Company (The)', 'sector': 'Consumer Defensive', 'symbol': 'KO'}, page_content='Powerade, Topo Chico, Core Power, Del Valle, fairlife, innocent, Maaza, Minute Maid, Minute Maid Pulpy, and Simply brands. It operates through a network of independent bottling partners, distributors, wholesalers, and retailers, as well as through bottling and distribution operators. The company was founded in 1886 and is headquartered in Atlanta, Georgia.'), -0.233447667864902), (Document(metadata={'name': 'Coca-Cola Company (The)', 'sector': 'Consumer Defensive', 'symbol': 'KO'}, page_content='Powerade, Topo Chico, Core Power, Del Valle, fairlife, innocent, Maaza, Minute Maid, Minute Maid Pulpy, and Simply brands. It operates through a network of independent bottling partners, distributors, wholesalers, and retailers, as well as through bottling and distribution operators. The company was founded in 1886 and is headquartered in Atlanta, Georgia.'), -0.233447667864902), (Document(metadata={'name': 'Coca-Cola Company (The)', 'sector': 'Consumer Defensive', 'symbol': 'KO'}, page_content='Powerade, Topo Chico, Core Power, Del Valle, fairlife, innocent, Maaza, Minute Maid, Minute Maid Pulpy, and Simply brands. It operates through a network of independent bottling partners, distributors, wholesalers, and retailers, as well as through bottling and distribution operators. The company was founded in 1886 and is headquartered in Atlanta, Georgia.'), -0.233447667864902)]\n",
      "  self.vectorstore.similarity_search_with_relevance_scores(\n",
      "No relevant docs were retrieved using the relevance score threshold 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know the answer.\n"
     ]
    }
   ],
   "source": [
    "query = \"who won the champions league in 2024?\"\n",
    "top3_docs = similarity_threshold_retriever.invoke(query)\n",
    "result = qa_rag_chain.invoke({\"context\": top3_docs, \"question\": query})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Query Rephraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM for question rewriting\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "# Prompt template for rewriting\n",
    "SYS_PROMPT = \"\"\"Act as a question re-writer and perform the following task:\n",
    "\t\t\t\t - Convert the following input question to a better version that is optimized for web search.\n",
    "\t\t\t\t - When re-writing, look at the input question and try to reason about the underlying semantic intent / meaning.\n",
    "\t\t\t \"\"\"\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "\t[\n",
    "\t\t(\"system\", SYS_PROMPT),\n",
    "\t\t(\"human\", \"\"\"Here is the initial question:\n",
    "\t\t\t\t\t {question}\n",
    "\t\t\t\t\t Formulate an improved question.\n",
    "\t\t\t\t  \"\"\")\n",
    "\t]\n",
    ")\n",
    "\n",
    "# Create rephraser chain\n",
    "question_rewriter = (re_write_prompt|llm|StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who was the winner of the UEFA Champions League in 2024?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"who won the champions league in 2024?\"\n",
    "question_rewriter.invoke({\"question\": query})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Web Search Tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tv_search = TavilySearchResults(max_results=3, search_depth='advanced', max_tokens=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB Config: {'dbname': 'postgres', 'user': 'postgres.qgoljxbwnlmvrutlylwp', 'password': 'WrWOSApFIXB2kI7E', 'host': 'aws-0-ap-southeast-1.pooler.supabase.com', 'port': 6543, 'sslmode': 'require'}\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": os.getenv(\"DBNAME\") or os.getenv(\"POSTGRES_DB\"),\n",
    "    \"user\": os.getenv(\"DBUSER\") or os.getenv(\"POSTGRES_USER\"),\n",
    "    \"password\": os.getenv(\"DBPASSWORD\") or os.getenv(\"POSTGRES_PASSWORD\"),\n",
    "    \"host\": os.getenv(\"DBHOST\") or \"localhost\",\n",
    "    \"port\": int(os.getenv(\"DBPORT\", 5432)),\n",
    "    \"sslmode\": os.getenv(\"SSL_MODE\", \"require\")\n",
    "}\n",
    "\n",
    "\n",
    "print(f\"DB Config: {DB_CONFIG}\")\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def connect_to_database():\n",
    "    try:\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        print(\"K·∫øt n·ªëi th√†nh c√¥ng ƒë·∫øn PostgreSQL.\")\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"L·ªói k·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_schema_and_samples(conn):\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT table_name FROM information_schema.tables WHERE table_schema='public';\")\n",
    "        tables = cursor.fetchall()\n",
    "        schema_info = {}\n",
    "        for (table,) in tables:\n",
    "            cursor.execute(f\"SELECT column_name, data_type FROM information_schema.columns WHERE table_name = '{table}';\")\n",
    "            schema_info[table] = [{\"column_name\": col, \"data_type\": dtype} for col, dtype in cursor.fetchall()]\n",
    "            cursor.execute(f'SELECT * FROM \"{table}\" LIMIT 3;')\n",
    "            sample_rows = cursor.fetchall()\n",
    "            colnames = [desc[0] for desc in cursor.description]\n",
    "            schema_info[f\"{table}_samples\"] = [dict(zip(colnames, row)) for row in sample_rows]\n",
    "        cursor.close()\n",
    "        return schema_info\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def generate_sql_query(user_question, schema_info=None):\n",
    "    prompt = f\"\"\"\n",
    "You are a PostgreSQL expert. You are working with a financial database containing two structured tables: \"djia_prices\" and \"djia_companies\".\n",
    "\n",
    "IMPORTANT:\n",
    "PostgreSQL is case-sensitive **only when using quoted identifiers**.\n",
    "You MUST wrap column names in double quotes (e.g. \"Ticker\", \"Close\", \"Date\", etc.)\n",
    "Do NOT use unquoted identifiers like Ticker or Close - they will cause errors.\n",
    "\n",
    "Table 1: \"djia_prices\" - Daily stock trading data per company\n",
    "- \"Date\" (TIMESTAMPTZ): The timestamp of the trading day.\n",
    "- \"Open\" (FLOAT): Opening price of the stock on that day.\n",
    "- \"High\" (FLOAT): Highest price reached during the trading day.\n",
    "- \"Low\" (FLOAT): Lowest price of the stock during the trading day.\n",
    "- \"Close\" (FLOAT): Closing price of the stock on that day.\n",
    "- \"Volume\" (BIGINT): Number of shares traded on that day.\n",
    "- \"Dividends\" (FLOAT): Dividend payout on that day, if any.\n",
    "- \"Stock_Splits\" (FLOAT): Stock split ratio applied on that day (e.g. 2.0 = 2-for-1 split).\n",
    "- \"Ticker\" (VARCHAR): The stock symbol of the company (e.g., AAPL, MSFT).\n",
    "\n",
    "Table 2: \"djia_companies\" - Company profile information\n",
    "- \"symbol\" (VARCHAR): The stock symbol matching the \"Ticker\" in \"djia_prices\".\n",
    "- \"name\" (TEXT): Full name of the company.\n",
    "- \"sector\" (TEXT): Main sector of operation (e.g., Technology, Healthcare).\n",
    "- \"industry\" (TEXT): More specific industry classification (e.g., Consumer Electronics).\n",
    "- \"country\" (TEXT): Country where the company is headquartered.\n",
    "- \"market_cap\" (FLOAT): Market capitalization in USD.\n",
    "- \"pe_ratio\" (FLOAT): Price-to-Earnings ratio of the company.\n",
    "- \"dividend_yield\" (FLOAT): Annual dividend yield expressed as a percentage.\n",
    "- \"description\" (TEXT): A short textual description of the company's operations.\n",
    "\n",
    "Use this schema to write the most accurate and optimized PostgreSQL query to answer the following question.\n",
    "\n",
    "Do NOT format the query in markdown or explain the result.\n",
    "Return ONLY the raw SQL.\n",
    "\n",
    "User Question:\n",
    "{user_question}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        sql_query = response.choices[0].message.content\n",
    "        sql_query = re.sub(r'^```sql', '', sql_query).strip('` \\n')\n",
    "        return sql_query\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói sinh SQL: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def execute_sql_query(conn, query):\n",
    "    try:\n",
    "        df = pd.read_sql(query, conn)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói th·ª±c thi SQL: {e}\")\n",
    "        return None\n",
    "\n",
    "def run_chat(question: str):\n",
    "    conn = connect_to_database()\n",
    "    if conn is None:\n",
    "        return\n",
    "\n",
    "    schema_info = get_schema_and_samples(conn)\n",
    "    sql_query = generate_sql_query(question, schema_info)\n",
    "\n",
    "    if not sql_query:\n",
    "        print(\"‚ùå Kh√¥ng th·ªÉ sinh truy v·∫•n SQL.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nüß† SQL sinh ra:\\n{sql_query}\")\n",
    "    results = execute_sql_query(conn, sql_query)\n",
    "\n",
    "    if results is None:\n",
    "        print(\"‚ùå Truy v·∫•n l·ªói.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nüìä K·∫øt qu·∫£:\")\n",
    "    print(results.head(5))\n",
    "\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Agentic RAG components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search_needed: str\n",
    "    documents: List[str]\n",
    "documents: List[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve function for retrieval from Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "\tprint(\"---RETRIEVAL FROM VECTOR DB---\")\n",
    "\tquestion = state[\"question\"]\n",
    "\t# Retrieval\n",
    "\tdocuments = similarity_threshold_retriever.invoke(question)\n",
    "\treturn {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grade documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state):\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state.get(\"documents\", [])\n",
    "\n",
    "    filtered_docs = []\n",
    "\n",
    "    if documents:\n",
    "        for d in documents:\n",
    "            score = doc_grader.invoke(\n",
    "                {\"question\": question, \"document\": d.page_content}\n",
    "            )\n",
    "            grade = score.strip().lower()\n",
    "\n",
    "            if grade == \"yes\":\n",
    "                print(\"‚úÖ GRADE: DOCUMENT RELEVANT\")\n",
    "                filtered_docs.append(d)\n",
    "            else:\n",
    "                print(\"‚ùå GRADE: DOCUMENT NOT RELEVANT\")\n",
    "    else:\n",
    "        print(\"Kh√¥ng c√≥ t√†i li·ªáu n√†o t·ª´ vector DB.\")\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"documents\": filtered_docs\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rewrite query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_query(state):\n",
    "    print(\"---REWRITE QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    # Re-write question\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"documents\": documents, \"question\": better_question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.schema import Document\n",
    "from finance_metrics import load_formulas, identify_metric, get_required_fields, compute_metric\n",
    "from plot_metric import plot_metric\n",
    "\n",
    "def query_sql(state):\n",
    "    print(\"---EXECUTE RAW SQL QUERY OR METRIC COMPUTATION---\")\n",
    "    question = state[\"question\"]\n",
    "    metadata = load_formulas()\n",
    "    category, metric_name = identify_metric(question, metadata)\n",
    "\n",
    "    # K·∫øt n·ªëi ƒë·∫øn DB\n",
    "    conn = connect_to_database()\n",
    "    if conn is None:\n",
    "        raise ValueError(\"Kh√¥ng th·ªÉ k·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu.\")\n",
    "\n",
    "    # N·∫øu l√† ch·ªâ s·ªë t√†i ch√≠nh (FA ho·∫∑c TA)\n",
    "    if metric_name:\n",
    "        print(f\"üìå Nh·∫≠n di·ªán ch·ªâ s·ªë: {metric_name} ({category})\")\n",
    "\n",
    "        # --- TA: V·∫Ω bi·ªÉu ƒë·ªì t·ª´ d·ªØ li·ªáu gi√° ---\n",
    "        if category == \"TA\":\n",
    "            df = pd.read_sql(\n",
    "                'SELECT \"Date\", \"Close\" FROM djia_prices WHERE \"Ticker\" = \\'AAPL\\' ORDER BY \"Date\" ASC LIMIT 100',\n",
    "                conn\n",
    "            )\n",
    "            conn.close()\n",
    "            df.rename(columns={\"Date\": \"date\", \"Close\": \"price\"}, inplace=True)\n",
    "\n",
    "            image_base64 = plot_metric(metric_name, df)\n",
    "            result_doc = Document(\n",
    "                page_content=f\"Bi·ªÉu ƒë·ªì {metric_name} cho AAPL:\",\n",
    "                metadata={\"image_base64\": image_base64}\n",
    "            )\n",
    "            return {\n",
    "                \"documents\": state[\"documents\"] + [result_doc],\n",
    "                \"question\": question\n",
    "            }\n",
    "\n",
    "        # --- FA: T√≠nh to√°n ch·ªâ s·ªë t·ª´ b·∫£ng c√¥ng ty ---\n",
    "        elif category == \"FA\":\n",
    "            required_fields = get_required_fields(category, metric_name, metadata)\n",
    "            query = f\"SELECT {', '.join(required_fields)} FROM djia_companies WHERE symbol = 'AAPL' LIMIT 1;\"\n",
    "            df = pd.read_sql(query, conn)\n",
    "            conn.close()\n",
    "\n",
    "            if df.empty:\n",
    "                result_str = f\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ t√≠nh {metric_name}.\"\n",
    "            else:\n",
    "                result = compute_metric(metric_name, df.iloc[0].to_dict())\n",
    "                result_str = f\"{metric_name} = {result}\"\n",
    "\n",
    "            return {\n",
    "                \"documents\": state[\"documents\"] + [Document(page_content=result_str)],\n",
    "                \"question\": question\n",
    "            }\n",
    "\n",
    "    # Tr∆∞·ªùng h·ª£p kh√¥ng ph·∫£i ch·ªâ s·ªë ‚Üí x·ª≠ l√Ω nh∆∞ SQL t·ª± nhi√™n\n",
    "    schema_info = get_schema_and_samples(conn)\n",
    "    sql_query = generate_sql_query(question, schema_info)\n",
    "    if not sql_query:\n",
    "        conn.close()\n",
    "        raise ValueError(\"Kh√¥ng th·ªÉ sinh truy v·∫•n SQL t·ª´ c√¢u h·ªèi.\")\n",
    "\n",
    "    results = execute_sql_query(conn, sql_query)\n",
    "    conn.close()\n",
    "\n",
    "    # ‚ö†Ô∏è N·∫øu kh√¥ng c√≥ d·ªØ li·ªáu ‚Üí y√™u c·∫ßu fallback web search\n",
    "    if results is None or results.empty:\n",
    "        content = \"‚ö†Ô∏è Kh√¥ng c√≥ k·∫øt qu·∫£ t·ª´ truy v·∫•n SQL.\"\n",
    "        state[\"web_search_needed\"] = \"Yes\"\n",
    "    else:\n",
    "        content = f\"üìä K·∫øt qu·∫£ t·ª´ truy v·∫•n SQL:\\n\\n{results.to_markdown(index=False)}\"\n",
    "\n",
    "    doc = Document(page_content=content)\n",
    "\n",
    "    return {\n",
    "        \"documents\": state[\"documents\"] + [doc],\n",
    "        \"question\": question,\n",
    "        \"sql_query\": sql_query,\n",
    "        \"web_search_needed\": state.get(\"web_search_needed\", \"No\")  # v·∫´n duy tr√¨ tr·∫°ng th√°i fallback\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### decide merge or query sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_merge_or_sql(state):\n",
    "    docs = state.get(\"documents\", [])\n",
    "    if len(docs) >= 1:\n",
    "        return \"merge_documents\"\n",
    "    return \"query_sql\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def merge_documents(state):\n",
    "    vector_docs = state.get(\"documents\", [])\n",
    "    sql_doc = state.get(\"sql_result\", None)\n",
    "\n",
    "    if sql_doc:\n",
    "        merged_docs = vector_docs + [sql_doc]\n",
    "    else:\n",
    "        merged_docs = vector_docs\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"documents\": merged_docs\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decide web search or generate answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_after_sql(state):\n",
    "    if state.get(\"web_search_needed\", \"No\") == \"Yes\":\n",
    "        print(\"---DECISION: Missing SQL data ‚Üí web search---\")\n",
    "        return \"rewrite_query\"\n",
    "    \n",
    "    print(\"---DECISION: Sufficient SQL data ‚Üí generate answer---\")\n",
    "    return \"generate_answer\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based on the re-written question.\n",
    "    Args:\n",
    "    state (dict): The current graph state\n",
    "    Returns:\n",
    "    state (dict): Updates documents key with appended web results\n",
    "    \"\"\"\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Web search\n",
    "    docs = tv_search.invoke(question)\n",
    "    \n",
    "    # G·ª° l·ªói: ki·ªÉm tra c·∫•u tr√∫c tr·∫£ v·ªÅ\n",
    "    print(\"DOCS TYPE:\", type(docs))\n",
    "    print(\"FIRST ELEMENT TYPE:\", type(docs[0]) if docs else \"EMPTY\")\n",
    "\n",
    "    # N·∫øu docs l√† list of strings\n",
    "    if isinstance(docs[0], str):\n",
    "        web_content = \"\\n\\n\".join(docs)\n",
    "    # N·∫øu docs l√† list of dicts\n",
    "    elif isinstance(docs[0], dict) and \"content\" in docs[0]:\n",
    "        web_content = \"\\n\\n\".join([d[\"content\"] for d in docs])\n",
    "    # N·∫øu docs l√† list of Document\n",
    "    elif isinstance(docs[0], Document):\n",
    "        web_content = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "    else:\n",
    "        raise TypeError(\"Unsupported doc format\")\n",
    "\n",
    "    web_results = Document(page_content=web_content)\n",
    "    documents.append(web_results)\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state):\n",
    "    print(\"---GENERATE ANSWER---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    # RAG generation\n",
    "    generation = qa_rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question,\"generation\": generation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Agent Graph with LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# --- Build enhanced Agentic RAG with SQL-priority + Vector fallback + multi-hop merge ---\n",
    "agentic_rag = StateGraph(GraphState)\n",
    "\n",
    "# Add nodes\n",
    "agentic_rag.add_node(\"retrieve\", retrieve)\n",
    "agentic_rag.add_node(\"grade_documents\", grade_documents)\n",
    "agentic_rag.add_node(\"merge_documents\", merge_documents)  # New: combine vector + SQL docs if relevant\n",
    "agentic_rag.add_node(\"query_sql\", query_sql)              # Always query SQL early\n",
    "agentic_rag.add_node(\"rewrite_query\", rewrite_query)\n",
    "agentic_rag.add_node(\"web_search\", web_search)\n",
    "agentic_rag.add_node(\"generate_answer\", generate_answer)\n",
    "\n",
    "# Entry point\n",
    "agentic_rag.set_entry_point(\"retrieve\")\n",
    "agentic_rag.add_edge(\"retrieve\", \"grade_documents\")\n",
    "\n",
    "# Sau grading ‚Üí n·∫øu t√†i li·ªáu vector ƒë·ªß t·ªët th√¨ merge lu√¥n\n",
    "agentic_rag.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_merge_or_sql,  # ‚Üí tr·∫£ v·ªÅ: \"merge_documents\" ho·∫∑c \"query_sql\"\n",
    "    {\n",
    "        \"merge_documents\": \"merge_documents\",\n",
    "        \"query_sql\": \"query_sql\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Sau merge ‚Üí lu√¥n th·ª±c hi·ªán SQL truy v·∫•n\n",
    "agentic_rag.add_edge(\"merge_documents\", \"query_sql\")\n",
    "\n",
    "# Sau query_sql ‚Üí n·∫øu ƒë·ªß ‚Üí generate, n·∫øu thi·∫øu ‚Üí web search\n",
    "agentic_rag.add_conditional_edges(\n",
    "    \"query_sql\",\n",
    "    decide_after_sql,\n",
    "    {\n",
    "        \"generate_answer\": \"generate_answer\",\n",
    "        \"rewrite_query\": \"rewrite_query\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Web search flow\n",
    "agentic_rag.add_edge(\"rewrite_query\", \"web_search\")\n",
    "agentic_rag.add_edge(\"web_search\", \"generate_answer\")\n",
    "\n",
    "# END\n",
    "agentic_rag.add_edge(\"generate_answer\", END)\n",
    "\n",
    "# Compile\n",
    "agentic_rag = agentic_rag.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langgraph.graph.state.CompiledStateGraph'>\n"
     ]
    }
   ],
   "source": [
    "print(type(agentic_rag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display, Markdown\n",
    "# display(Image(agentic_rag.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Agentic RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVAL FROM VECTOR DB---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\vectorstores\\base.py:1045: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'name': 'International Business Machines', 'sector': 'Technology', 'symbol': 'IBM'}, page_content=\"International Business Machines Corporation, together with its subsidiaries, provides integrated solutions and services in the United States, Europe, the Middle East, Africa, Asia Pacific, and internationally. It operates through Software, Consulting, Infrastructure, and Financing segments. The Software segment offers hybrid cloud and AI platforms that allows clients to realize their digital and AI transformations across the applications, data, and environments in which they operate. Its Consulting segment focuses on skills integration for strategy, experience, technology, and operations by domain and industry. The Infrastructure segment provides on-premises and cloud based server, and storage solutions, as well as life-cycle services for hybrid cloud infrastructure deployment. Its Financing segment offers client and commercial financing, facilitates IBM clients' acquisition of hardware, software, and services. It has a strategic partnership to various companies including hyperscalers,\"), -0.0243021929118985), (Document(metadata={'name': 'International Business Machines', 'sector': 'Technology', 'symbol': 'IBM'}, page_content=\"International Business Machines Corporation, together with its subsidiaries, provides integrated solutions and services in the United States, Europe, the Middle East, Africa, Asia Pacific, and internationally. It operates through Software, Consulting, Infrastructure, and Financing segments. The Software segment offers hybrid cloud and AI platforms that allows clients to realize their digital and AI transformations across the applications, data, and environments in which they operate. Its Consulting segment focuses on skills integration for strategy, experience, technology, and operations by domain and industry. The Infrastructure segment provides on-premises and cloud based server, and storage solutions, as well as life-cycle services for hybrid cloud infrastructure deployment. Its Financing segment offers client and commercial financing, facilitates IBM clients' acquisition of hardware, software, and services. It has a strategic partnership to various companies including hyperscalers,\"), -0.0243021929118985), (Document(metadata={'name': 'International Business Machines', 'sector': 'Technology', 'symbol': 'IBM'}, page_content=\"International Business Machines Corporation, together with its subsidiaries, provides integrated solutions and services in the United States, Europe, the Middle East, Africa, Asia Pacific, and internationally. It operates through Software, Consulting, Infrastructure, and Financing segments. The Software segment offers hybrid cloud and AI platforms that allows clients to realize their digital and AI transformations across the applications, data, and environments in which they operate. Its Consulting segment focuses on skills integration for strategy, experience, technology, and operations by domain and industry. The Infrastructure segment provides on-premises and cloud based server, and storage solutions, as well as life-cycle services for hybrid cloud infrastructure deployment. Its Financing segment offers client and commercial financing, facilitates IBM clients' acquisition of hardware, software, and services. It has a strategic partnership to various companies including hyperscalers,\"), -0.0243021929118985)]\n",
      "  self.vectorstore.similarity_search_with_relevance_scores(\n",
      "No relevant docs were retrieved using the relevance score threshold 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "Kh√¥ng c√≥ t√†i li·ªáu n√†o t·ª´ vector DB.\n",
      "---EXECUTE RAW SQL QUERY OR METRIC COMPUTATION---\n",
      "K·∫øt n·ªëi th√†nh c√¥ng ƒë·∫øn PostgreSQL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trung\\AppData\\Local\\Temp\\ipykernel_12536\\2693450380.py:99: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: Sufficient SQL data ‚Üí generate answer---\n",
      "---GENERATE ANSWER---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The companies in the DJIA that have a P/E ratio greater than 25 are:\n",
       "\n",
       "- Apple Inc.\n",
       "- Amgen Inc.\n",
       "- Salesforce, Inc.\n",
       "- Walt Disney Company (The)\n",
       "- Dow Inc.\n",
       "- International Business Machines\n",
       "- Coca-Cola Company (The)\n",
       "- McDonald's Corporation\n",
       "- Microsoft Corporation\n",
       "- Procter & Gamble Company (The)\n",
       "- Visa Inc.\n",
       "- Walmart Inc.\n",
       "\n",
       "These are the companies listed in the provided context as having a P/E ratio above 25."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Which companies in the DJIA have a P/E ratio greater than 25?\"\n",
    "response = agentic_rag.invoke({\"question\": query})\n",
    "display(Markdown(response['generation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVAL FROM VECTOR DB---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\vectorstores\\base.py:1045: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'name': 'Dow Inc.', 'sector': 'Basic Materials', 'symbol': 'DOW'}, page_content='Dow Inc., through its subsidiaries, provides various materials science solutions for packaging, infrastructure, mobility, and consumer applications in the United States, Canada, Europe, the Middle East, Africa, India, the Asia Pacific, and Latin America. The company operates through Packaging & Specialty Plastics, Industrial Intermediates & Infrastructure, and Performance Materials & Coatings segments. The Packaging & Specialty Plastics segment provides ethylene, propylene, polyethylene, and aromatics products; and other ethylene derivatives, such as polyolefin elastomers, ethylene vinyl acetate, and ethylene propylene diene monomer rubber. The Industrial Intermediates & Infrastructure segment offers polyurethanes, including propylene oxide, propylene glycol, and polyether polyols; aromatic isocyanates and fully formulated polyurethane systems; and chlor-alkali and vinyl comprising chlorine and caustic soda, ethylene dichloride, and vinyl chloride monomer; and construction chemicals'), -0.06640057254700493), (Document(metadata={'name': 'Dow Inc.', 'sector': 'Basic Materials', 'symbol': 'DOW'}, page_content='Dow Inc., through its subsidiaries, provides various materials science solutions for packaging, infrastructure, mobility, and consumer applications in the United States, Canada, Europe, the Middle East, Africa, India, the Asia Pacific, and Latin America. The company operates through Packaging & Specialty Plastics, Industrial Intermediates & Infrastructure, and Performance Materials & Coatings segments. The Packaging & Specialty Plastics segment provides ethylene, propylene, polyethylene, and aromatics products; and other ethylene derivatives, such as polyolefin elastomers, ethylene vinyl acetate, and ethylene propylene diene monomer rubber. The Industrial Intermediates & Infrastructure segment offers polyurethanes, including propylene oxide, propylene glycol, and polyether polyols; aromatic isocyanates and fully formulated polyurethane systems; and chlor-alkali and vinyl comprising chlorine and caustic soda, ethylene dichloride, and vinyl chloride monomer; and construction chemicals'), -0.0664136380700433), (Document(metadata={'name': 'Dow Inc.', 'sector': 'Basic Materials', 'symbol': 'DOW'}, page_content='Dow Inc., through its subsidiaries, provides various materials science solutions for packaging, infrastructure, mobility, and consumer applications in the United States, Canada, Europe, the Middle East, Africa, India, the Asia Pacific, and Latin America. The company operates through Packaging & Specialty Plastics, Industrial Intermediates & Infrastructure, and Performance Materials & Coatings segments. The Packaging & Specialty Plastics segment provides ethylene, propylene, polyethylene, and aromatics products; and other ethylene derivatives, such as polyolefin elastomers, ethylene vinyl acetate, and ethylene propylene diene monomer rubber. The Industrial Intermediates & Infrastructure segment offers polyurethanes, including propylene oxide, propylene glycol, and polyether polyols; aromatic isocyanates and fully formulated polyurethane systems; and chlor-alkali and vinyl comprising chlorine and caustic soda, ethylene dichloride, and vinyl chloride monomer; and construction chemicals'), -0.0664165883494392)]\n",
      "  self.vectorstore.similarity_search_with_relevance_scores(\n",
      "No relevant docs were retrieved using the relevance score threshold 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "Kh√¥ng c√≥ t√†i li·ªáu n√†o t·ª´ vector DB.\n",
      "---EXECUTE RAW SQL QUERY OR METRIC COMPUTATION---\n",
      "K·∫øt n·ªëi th√†nh c√¥ng ƒë·∫øn PostgreSQL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trung\\AppData\\Local\\Temp\\ipykernel_12536\\2693450380.py:99: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: Sufficient SQL data ‚Üí generate answer---\n",
      "---GENERATE ANSWER---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The companies whose average closing price in the last 90 days is above 200 and have a P/E ratio lower than 20 are:\n",
       "\n",
       "1. Caterpillar, Inc. (CAT)  \n",
       "   - Average Closing Price: 324.451  \n",
       "   - P/E Ratio: 13.8917\n",
       "\n",
       "2. UnitedHealth Group Incorporated (UNH)  \n",
       "   - Average Closing Price: 502.269  \n",
       "   - P/E Ratio: 17.5163\n",
       "\n",
       "3. The Travelers Companies, Inc. (TRV)  \n",
       "   - Average Closing Price: 253.19  \n",
       "   - P/E Ratio: 14.1078\n",
       "\n",
       "4. American Express Company (AXP)  \n",
       "   - Average Closing Price: 271.41  \n",
       "   - P/E Ratio: 18.4794\n",
       "\n",
       "5. JP Morgan Chase & Co. (JPM)  \n",
       "   - Average Closing Price: 243.498  \n",
       "   - P/E Ratio: 11.9446\n",
       "\n",
       "6. Goldman Sachs Group, Inc. (GS)  \n",
       "   - Average Closing Price: 559.867  \n",
       "   - P/E Ratio: 12.6418\n",
       "\n",
       "All these companies meet the criteria of having an average closing price above 200 and a P/E ratio below 20."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"List companies whose average closing price in the last 90 days is above 200 and have a P/E ratio lower than 20.\"\n",
    "response = agentic_rag.invoke({\"question\": query})\n",
    "display(Markdown(response['generation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. C√¢u h·ªèi t·∫≠p trung v√†o ch·ªâ s·ªë t√†i ch√≠nh (EPS, P/E, dividend, market cap):\n",
    "- Which companies in the DJIA have a P/E ratio greater than 25?\n",
    "\n",
    "- List the top 5 companies with the highest market capitalization and show their dividend yield and P/E ratio.\n",
    "\n",
    "- What is the average P/E ratio of companies in the Technology sector?\n",
    "\n",
    "- Show all companies with a dividend yield greater than 3% and market cap over 500 billion USD.\n",
    "\n",
    "- Find all companies where the P/E ratio is less than the average P/E ratio across all DJIA companies.\n",
    "\n",
    "2. C√¢u h·ªèi k·∫øt h·ª£p djia_prices + djia_companies (g·ª£i √Ω v·ªÅ EPS qua Close):\n",
    "- Calculate the average closing price of Apple (AAPL) over the past 30 days.\n",
    "\n",
    "- For each company, calculate the maximum daily trading volume in the last 6 months.\n",
    "\n",
    "- List companies whose average closing price in the last 90 days is above 200 and have a P/E ratio lower than 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîÅ Lu·ªìng th·ª±c thi t·ª´ng b∆∞·ªõc\n",
    "üü© 1. retrieve\n",
    "Truy xu·∫•t t√†i li·ªáu t·ª´ vector DB (Chroma)\n",
    "\n",
    "C√¢u h·ªèi ng∆∞·ªùi d√πng ƒë∆∞·ª£c d√πng ƒë·ªÉ t√¨m c√°c ƒëo·∫°n vƒÉn m√¥ t·∫£ c√¥ng ty, ng√†nh, ho·∫∑c ki·∫øn th·ª©c li√™n quan\n",
    "\n",
    "üü¶ 2. grade_documents\n",
    "D√πng LLM ƒë·ªÉ ƒë√°nh gi√° m·ª©c ƒë·ªô li√™n quan c·ªßa c√°c ƒëo·∫°n t√†i li·ªáu t√¨m ƒë∆∞·ª£c\n",
    "\n",
    "N·∫øu ƒë·ªß li√™n quan, h·ªá th·ªëng ƒë√°nh d·∫•u l√† t√†i li·ªáu c√≥ th·ªÉ d√πng ƒë·ªÉ tr·∫£ l·ªùi\n",
    "\n",
    "üîÅ 3. Nh√°nh r·∫Ω decide_merge_or_sql:\n",
    "N·∫øu t√†i li·ªáu li√™n quan t·ªët ‚Üí chuy·ªÉn sang merge_documents\n",
    "\n",
    "N·∫øu t√†i li·ªáu y·∫øu / kh√¥ng ƒë·ªß ‚Üí ƒëi th·∫≥ng ƒë·∫øn query_sql ƒë·ªÉ truy v·∫•n d·ªØ li·ªáu c√≥ c·∫•u tr√∫c\n",
    "\n",
    "üî∑ 4. merge_documents (m·ªõi th√™m)\n",
    "K·∫øt h·ª£p t√†i li·ªáu vector (phi c·∫•u tr√∫c) v·ªõi k·∫øt qu·∫£ SQL (c·∫•u tr√∫c) ƒë·ªÉ t·∫°o ƒë·∫ßu v√†o to√†n di·ªán cho LLM\n",
    "\n",
    "H·ªØu √≠ch trong tr∆∞·ªùng h·ª£p: \"Gi√° c·ªï phi·∫øu trong 30 ng√†y qua v√† c√¥ng ty ho·∫°t ƒë·ªông trong lƒ©nh v·ª±c n√†o?\"\n",
    "\n",
    "üü® 5. query_sql\n",
    "Th·ª±c hi·ªán truy v·∫•n d·ªØ li·ªáu b·∫£ng t·ª´ PostgreSQL (v√≠ d·ª•: djia_prices, djia_companies)\n",
    "\n",
    "T·ª± ƒë·ªông x·ª≠ l√Ω c√°c truy v·∫•n li√™n quan ƒë·∫øn ch·ªâ s·ªë FA/TA n·∫øu ph√°t hi·ªán (P/E, RSI, v.v.)\n",
    "\n",
    "üîÅ 6. Nh√°nh r·∫Ω decide_after_sql:\n",
    "N·∫øu d·ªØ li·ªáu b·∫£ng ƒë·ªß ƒë·ªÉ tr·∫£ l·ªùi ‚Üí chuy·ªÉn ƒë·∫øn generate_answer\n",
    "\n",
    "N·∫øu d·ªØ li·ªáu thi·∫øu ho·∫∑c kh√¥ng t√¨m th·∫•y ‚Üí sang rewrite_query ƒë·ªÉ chu·∫©n b·ªã cho web search\n",
    "\n",
    "üåê 7. rewrite_query ‚Üí web_search\n",
    "LLM vi·∫øt l·∫°i c√¢u h·ªèi ƒë·ªÉ t·ªëi ∆∞u h√≥a k·∫øt qu·∫£ khi g·ª≠i l√™n API t√¨m ki·∫øm (Tavily)\n",
    "\n",
    "Sau ƒë√≥ th·ª±c hi·ªán web_search v√† l·∫•y th√¥ng tin t·ª´ web\n",
    "\n",
    "üß† 8. generate_answer\n",
    "LLM t·ªïng h·ª£p c√°c th√¥ng tin t·ª´ SQL, vector, v√†/ho·∫∑c web ƒë·ªÉ sinh ra c√¢u tr·∫£ l·ªùi cu·ªëi c√πng\n",
    "\n",
    "‚úÖ 9. END\n",
    "Tr·∫£ k·∫øt qu·∫£ v·ªÅ cho ng∆∞·ªùi d√πng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
