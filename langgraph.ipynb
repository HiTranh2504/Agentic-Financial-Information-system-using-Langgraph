{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start LangGraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain==0.2.0\n",
    "# !pip install langchain-openai==0.1.7\n",
    "# !pip install langchain-community==0.2.0\n",
    "# !pip install langgraph==0.1.1\n",
    "# !pip install langchain-chroma==0.1.1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use file .env to get the API key\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_KEY\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Vector Database for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "openai_embed_model = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "import pandas as pd\n",
    "\n",
    "companies_df = pd.read_csv(\"Data Kien/djia_companies_20250426.csv\")\n",
    "companies_df.head()\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=row['description'],\n",
    "        metadata={'symbol': row['symbol'], 'name': row['name'], 'sector': row['sector']}\n",
    "    )\n",
    "    for _, row in companies_df.iterrows()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "chunked_docs = splitter.split_documents(docs)\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embed_model = OpenAIEmbeddings(model='text-embedding-3-small')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "chroma_db = Chroma.from_documents(\n",
    "    documents=chunked_docs,\n",
    "    embedding=embed_model,\n",
    "    collection_name='djia_company_info',\n",
    "    persist_directory=\"./djia_vector_db\"\n",
    ")\n",
    "similarity_threshold_retriever  = chroma_db.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"k\": 3, \"score_threshold\": 0.3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Inc. -> Apple Inc. designs, manufactures, and markets smartphones, personal computers, tablets, wearables, and accessories worldwide. The company offers iPhone, a line of smartphones; Mac, a line of personal \n",
      "Apple Inc. -> Apple Inc. designs, manufactures, and markets smartphones, personal computers, tablets, wearables, and accessories worldwide. The company offers iPhone, a line of smartphones; Mac, a line of personal \n",
      "Apple Inc. -> Apple Inc. designs, manufactures, and markets smartphones, personal computers, tablets, wearables, and accessories worldwide. The company offers iPhone, a line of smartphones; Mac, a line of personal \n"
     ]
    }
   ],
   "source": [
    "query = \"What does Apple do?\"\n",
    "results = similarity_threshold_retriever .invoke(query)\n",
    "for r in results:\n",
    "    print(r.metadata['name'], \"->\", r.page_content[:200])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Query Retrieval Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# T·∫°o LLM v·ªõi c·∫•u h√¨nh Pydantic V2\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# Parser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Prompt system\n",
    "SYS_PROMPT = \"\"\"\n",
    "You are an expert grader assessing relevance of a retrieved document to a user question.\n",
    "Answer only 'yes' or 'no' depending on whether the document is relevant to the question.\n",
    "\"\"\"\n",
    "\n",
    "# T·∫°o prompt template\n",
    "grade_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", SYS_PROMPT),\n",
    "    (\"human\", \"Retrieved document:\\n{document}\\n\\nUser question:\\n{question}\")\n",
    "])\n",
    "\n",
    "# T·∫°o chain x·ª≠ l√Ω\n",
    "doc_grader = grade_prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Inc. designs, manufactures, and markets smartphones, personal computers, tablets, wearables, and accessories worldwide. The company offers iPhone, a line of smartphones; Mac, a line of personal computers; iPad, a line of multi-purpose tablets; and wearables, home, and accessories comprising AirPods, Apple TV, Apple Watch, Beats products, and HomePod. It also provides AppleCare support and cloud services; and operates various platforms, including the App Store that allow customers to discover and download applications and digital content, such as books, music, video, games, and podcasts, as well as advertising services include third-party licensing arrangements and its own advertising platforms. In addition, the company offers various subscription-based services, such as Apple Arcade, a game subscription service; Apple Fitness+, a personalized fitness service; Apple Music, which offers users a curated listening experience with on-demand radio stations; Apple News+, a subscription\n",
      "GRADE: yes\n",
      "\n",
      "Apple Inc. designs, manufactures, and markets smartphones, personal computers, tablets, wearables, and accessories worldwide. The company offers iPhone, a line of smartphones; Mac, a line of personal computers; iPad, a line of multi-purpose tablets; and wearables, home, and accessories comprising AirPods, Apple TV, Apple Watch, Beats products, and HomePod. It also provides AppleCare support and cloud services; and operates various platforms, including the App Store that allow customers to discover and download applications and digital content, such as books, music, video, games, and podcasts, as well as advertising services include third-party licensing arrangements and its own advertising platforms. In addition, the company offers various subscription-based services, such as Apple Arcade, a game subscription service; Apple Fitness+, a personalized fitness service; Apple Music, which offers users a curated listening experience with on-demand radio stations; Apple News+, a subscription\n",
      "GRADE: yes\n",
      "\n",
      "Apple Inc. designs, manufactures, and markets smartphones, personal computers, tablets, wearables, and accessories worldwide. The company offers iPhone, a line of smartphones; Mac, a line of personal computers; iPad, a line of multi-purpose tablets; and wearables, home, and accessories comprising AirPods, Apple TV, Apple Watch, Beats products, and HomePod. It also provides AppleCare support and cloud services; and operates various platforms, including the App Store that allow customers to discover and download applications and digital content, such as books, music, video, games, and podcasts, as well as advertising services include third-party licensing arrangements and its own advertising platforms. In addition, the company offers various subscription-based services, such as Apple Arcade, a game subscription service; Apple Fitness+, a personalized fitness service; Apple Music, which offers users a curated listening experience with on-demand radio stations; Apple News+, a subscription\n",
      "GRADE: yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What does Apple do?\"\n",
    "top3_docs = similarity_threshold_retriever.invoke(query)\n",
    "for doc in top3_docs:\n",
    "\tprint(doc.page_content)\n",
    "\tprint('GRADE:', doc_grader.invoke({\n",
    "\t\t\"question\": query,\n",
    "\t\t\"document\": doc.page_content\n",
    "\t}))\n",
    "\tprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a QA RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "\n",
    "# Create RAG prompt for response generation\n",
    "prompt = \"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If no context is present or if you don't know the answer, just say that you don't know the answer.\n",
    "Do not make up the answer unless it is there in the provided context.\n",
    "Give a detailed answer and to the point answer with regard to the question.\n",
    "Question:\n",
    "{question}\n",
    "Context:\n",
    "{context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(prompt)\n",
    "\n",
    "# Initialize connection with gpt-4.1-mini\n",
    "chatgpt = ChatOpenAI(model_name='gpt-4.1-mini', temperature=0)\n",
    "\n",
    "# Used for separating context docs with new lines\n",
    "def format_docs(docs):\n",
    "\treturn \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Create QA RAG chain\n",
    "qa_rag_chain = (\n",
    "\t{\n",
    "\t\t\"context\": (itemgetter('context')\n",
    "\t\t\t\t\t|\n",
    "\t\t\t\t\tRunnableLambda(format_docs)),\n",
    "\t\t\"question\": itemgetter('question')\n",
    "\t}\n",
    "\t|\n",
    "\tprompt_template\n",
    "\t|\n",
    "\tchatgpt\n",
    "\t|\n",
    "\tStrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Inc. designs, manufactures, and markets a wide range of technology products and services worldwide. Its product lineup includes smartphones (iPhone), personal computers (Mac), multi-purpose tablets (iPad), and various wearables and accessories such as AirPods, Apple TV, Apple Watch, Beats products, and HomePod. Beyond hardware, Apple provides AppleCare support and cloud services. The company also operates digital platforms like the App Store, which enables customers to discover and download applications and digital content including books, music, videos, games, and podcasts. Additionally, Apple offers advertising services through third-party licensing and its own advertising platforms. It also provides several subscription-based services, including Apple Arcade (a game subscription service), Apple Fitness+ (a personalized fitness service), Apple Music (a curated music streaming service), and Apple News+ (a subscription news service).\n"
     ]
    }
   ],
   "source": [
    "query = \"What does Apple do?\"\n",
    "top3_docs = similarity_threshold_retriever.invoke(query)\n",
    "result = qa_rag_chain.invoke({\"context\": top3_docs, \"question\": query})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\HK2_2024_2025\\Data Platform\\Thuc_hanh\\CK\\venv\\lib\\site-packages\\langchain_core\\vectorstores\\base.py:1082: UserWarning: Relevance scores must be between 0 and 1, got [(Document(id='0c8d1bba-71ab-43aa-952d-5db38c1edd95', metadata={'name': 'Coca-Cola Company (The)', 'sector': 'Consumer Defensive', 'symbol': 'KO'}, page_content='Powerade, Topo Chico, Core Power, Del Valle, fairlife, innocent, Maaza, Minute Maid, Minute Maid Pulpy, and Simply brands. It operates through a network of independent bottling partners, distributors, wholesalers, and retailers, as well as through bottling and distribution operators. The company was founded in 1886 and is headquartered in Atlanta, Georgia.'), -0.23370375211645422), (Document(id='5dc2715a-e77e-4547-ae84-d7fdcb406a9d', metadata={'name': 'Coca-Cola Company (The)', 'sector': 'Consumer Defensive', 'symbol': 'KO'}, page_content='Powerade, Topo Chico, Core Power, Del Valle, fairlife, innocent, Maaza, Minute Maid, Minute Maid Pulpy, and Simply brands. It operates through a network of independent bottling partners, distributors, wholesalers, and retailers, as well as through bottling and distribution operators. The company was founded in 1886 and is headquartered in Atlanta, Georgia.'), -0.23370543799039467), (Document(id='97b56757-0bd8-4889-95e6-200fa9b853a4', metadata={'name': 'Coca-Cola Company (The)', 'sector': 'Consumer Defensive', 'symbol': 'KO'}, page_content='Powerade, Topo Chico, Core Power, Del Valle, fairlife, innocent, Maaza, Minute Maid, Minute Maid Pulpy, and Simply brands. It operates through a network of independent bottling partners, distributors, wholesalers, and retailers, as well as through bottling and distribution operators. The company was founded in 1886 and is headquartered in Atlanta, Georgia.'), -0.2337560142086077)]\n",
      "  self.vectorstore.similarity_search_with_relevance_scores(\n",
      "No relevant docs were retrieved using the relevance score threshold 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know the answer.\n"
     ]
    }
   ],
   "source": [
    "query = \"who won the champions league in 2024?\"\n",
    "top3_docs = similarity_threshold_retriever.invoke(query)\n",
    "result = qa_rag_chain.invoke({\"context\": top3_docs, \"question\": query})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Query Rephraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM for question rewriting\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "# Prompt template for rewriting\n",
    "SYS_PROMPT = \"\"\"Act as a question re-writer and perform the following task:\n",
    "\t\t\t\t - Convert the following input question to a better version that is optimized for web search.\n",
    "\t\t\t\t - When re-writing, look at the input question and try to reason about the underlying semantic intent / meaning.\n",
    "\t\t\t \"\"\"\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "\t[\n",
    "\t\t(\"system\", SYS_PROMPT),\n",
    "\t\t(\"human\", \"\"\"Here is the initial question:\n",
    "\t\t\t\t\t {question}\n",
    "\t\t\t\t\t Formulate an improved question.\n",
    "\t\t\t\t  \"\"\")\n",
    "\t]\n",
    ")\n",
    "\n",
    "# Create rephraser chain\n",
    "question_rewriter = (re_write_prompt|llm|StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who was the winner of the UEFA Champions League in 2024?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"who won the champions league in 2024?\"\n",
    "question_rewriter.invoke({\"question\": query})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Web Search Tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tv_search = TavilySearchResults(max_results=3, search_depth='advanced', max_tokens=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB Config: {'dbname': 'postgres', 'user': 'postgres.qgoljxbwnlmvrutlylwp', 'password': 'WrWOSApFIXB2kI7E', 'host': 'aws-0-ap-southeast-1.pooler.supabase.com', 'port': 6543, 'sslmode': 'require'}\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": os.getenv(\"DBNAME\") or os.getenv(\"POSTGRES_DB\"),\n",
    "    \"user\": os.getenv(\"DBUSER\") or os.getenv(\"POSTGRES_USER\"),\n",
    "    \"password\": os.getenv(\"DBPASSWORD\") or os.getenv(\"POSTGRES_PASSWORD\"),\n",
    "    \"host\": os.getenv(\"DBHOST\") or \"localhost\",\n",
    "    \"port\": int(os.getenv(\"DBPORT\", 5432)),\n",
    "    \"sslmode\": os.getenv(\"SSL_MODE\", \"require\")\n",
    "}\n",
    "\n",
    "\n",
    "print(f\"DB Config: {DB_CONFIG}\")\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def connect_to_database():\n",
    "    try:\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        print(\"K·∫øt n·ªëi th√†nh c√¥ng ƒë·∫øn PostgreSQL.\")\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"L·ªói k·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_schema_and_samples(conn):\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT table_name FROM information_schema.tables WHERE table_schema='public';\")\n",
    "        tables = cursor.fetchall()\n",
    "        schema_info = {}\n",
    "        for (table,) in tables:\n",
    "            cursor.execute(f\"SELECT column_name, data_type FROM information_schema.columns WHERE table_name = '{table}';\")\n",
    "            schema_info[table] = [{\"column_name\": col, \"data_type\": dtype} for col, dtype in cursor.fetchall()]\n",
    "            cursor.execute(f'SELECT * FROM \"{table}\" LIMIT 3;')\n",
    "            sample_rows = cursor.fetchall()\n",
    "            colnames = [desc[0] for desc in cursor.description]\n",
    "            schema_info[f\"{table}_samples\"] = [dict(zip(colnames, row)) for row in sample_rows]\n",
    "        cursor.close()\n",
    "        return schema_info\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def generate_sql_query(user_question, schema_info=None):\n",
    "    prompt = f\"\"\"\n",
    "You are a PostgreSQL expert. You are working with a financial database containing two structured tables: \"djia_prices\" and \"djia_companies\".\n",
    "\n",
    "‚ö†Ô∏è IMPORTANT:\n",
    "PostgreSQL is case-sensitive **only when using quoted identifiers**.\n",
    "You MUST wrap column names in double quotes (e.g. \"Ticker\", \"Close\", \"Date\", etc.)\n",
    "Do NOT use unquoted identifiers like Ticker or Close ‚Äì they will cause errors.\n",
    "\n",
    "Table 1: \"djia_prices\" - Daily stock trading data per company\n",
    "- \"Date\" (TIMESTAMPTZ): The timestamp of the trading day.\n",
    "- \"Open\" (FLOAT): Opening price of the stock on that day.\n",
    "- \"High\" (FLOAT): Highest price reached during the trading day.\n",
    "- \"Low\" (FLOAT): Lowest price of the stock during the trading day.\n",
    "- \"Close\" (FLOAT): Closing price of the stock on that day.\n",
    "- \"Volume\" (BIGINT): Number of shares traded on that day.\n",
    "- \"Dividends\" (FLOAT): Dividend payout on that day, if any.\n",
    "- \"Stock_Splits\" (FLOAT): Stock split ratio applied on that day (e.g. 2.0 = 2-for-1 split).\n",
    "- \"Ticker\" (VARCHAR): The stock symbol of the company (e.g., AAPL, MSFT).\n",
    "\n",
    "Table 2: \"djia_companies\" - Company profile information\n",
    "- \"symbol\" (VARCHAR): The stock symbol matching the \"Ticker\" in \"djia_prices\".\n",
    "- \"name\" (TEXT): Full name of the company.\n",
    "- \"sector\" (TEXT): Main sector of operation (e.g., Technology, Healthcare).\n",
    "- \"industry\" (TEXT): More specific industry classification (e.g., Consumer Electronics).\n",
    "- \"country\" (TEXT): Country where the company is headquartered.\n",
    "- \"market_cap\" (FLOAT): Market capitalization in USD.\n",
    "- \"pe_ratio\" (FLOAT): Price-to-Earnings ratio of the company.\n",
    "- \"dividend_yield\" (FLOAT): Annual dividend yield expressed as a percentage.\n",
    "- \"description\" (TEXT): A short textual description of the company's operations.\n",
    "\n",
    "Use this schema to write the most accurate and optimized PostgreSQL query to answer the following question.\n",
    "\n",
    "Do NOT format the query in markdown or explain the result.\n",
    "Return ONLY the raw SQL.\n",
    "\n",
    "User Question:\n",
    "{user_question}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        sql_query = response.choices[0].message.content\n",
    "        sql_query = re.sub(r'^```sql', '', sql_query).strip('` \\n')\n",
    "        return sql_query\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói sinh SQL: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def execute_sql_query(conn, query):\n",
    "    try:\n",
    "        df = pd.read_sql(query, conn)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói th·ª±c thi SQL: {e}\")\n",
    "        return None\n",
    "\n",
    "def run_chat(question: str):\n",
    "    conn = connect_to_database()\n",
    "    if conn is None:\n",
    "        return\n",
    "\n",
    "    schema_info = get_schema_and_samples(conn)\n",
    "    sql_query = generate_sql_query(question, schema_info)\n",
    "\n",
    "    if not sql_query:\n",
    "        print(\"‚ùå Kh√¥ng th·ªÉ sinh truy v·∫•n SQL.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nüß† SQL sinh ra:\\n{sql_query}\")\n",
    "    results = execute_sql_query(conn, sql_query)\n",
    "\n",
    "    if results is None:\n",
    "        print(\"‚ùå Truy v·∫•n l·ªói.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nüìä K·∫øt qu·∫£:\")\n",
    "    print(results.head(5))\n",
    "\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Agentic RAG components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search_needed: str\n",
    "    documents: List[str]\n",
    "documents: List[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve function for retrieval from Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "\tprint(\"---RETRIEVAL FROM VECTOR DB---\")\n",
    "\tquestion = state[\"question\"]\n",
    "\t# Retrieval\n",
    "\tdocuments = similarity_threshold_retriever.invoke(question)\n",
    "\treturn {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grade documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state):\n",
    "\tprint(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "\tquestion = state[\"question\"]\n",
    "\tdocuments = state[\"documents\"]\n",
    "\n",
    "\tfiltered_docs = []\n",
    "\tweb_search_needed = \"No\"\n",
    "\tuse_sql = \"No\"\n",
    "\n",
    "\tif documents:\n",
    "\t\tfor d in documents:\n",
    "\t\t\tscore = doc_grader.invoke(\n",
    "\t\t\t\t{\"question\": question, \"document\": d.page_content}\n",
    "\t\t\t)\n",
    "\t\t\tgrade = score.strip().lower()\n",
    "\n",
    "\t\t\tif grade == \"yes\":\n",
    "\t\t\t\tprint(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "\t\t\t\tfiltered_docs.append(d)\n",
    "\t\t\telse:\n",
    "\t\t\t\t# Ph√¢n lo·∫°i theo n·ªôi dung\n",
    "\t\t\t\tif \"database\" in question.lower() or \"truy v·∫•n\" in question.lower() or \"from table\" in question.lower():\n",
    "\t\t\t\t\tuse_sql = \"Yes\"\n",
    "\t\t\t\t\tprint(\"---GRADE: DOCUMENT NOT RELEVANT, SUGGEST SQL---\")\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tweb_search_needed = \"Yes\"\n",
    "\t\t\t\t\tprint(\"---GRADE: DOCUMENT NOT RELEVANT, SUGGEST WEB SEARCH---\")\n",
    "\telse:\n",
    "\t\t# Ki·ªÉm tra n·ªôi dung c√¢u h·ªèi ‚Üí c√≥ ch·ª©a t·ª´ kh√≥a SQL\n",
    "\t\tif \"database\" in question.lower() or \"truy v·∫•n\" in question.lower() or \"from table\" in question.lower():\n",
    "\t\t\tuse_sql = \"Yes\"\n",
    "\t\t\tprint(\"---NO DOCS, BUT QUESTION SUGGESTS SQL---\")\n",
    "\t\telse:\n",
    "\t\t\tweb_search_needed = \"Yes\"\n",
    "\n",
    "\treturn {\n",
    "\t\t\"documents\": filtered_docs,\n",
    "\t\t\"question\": question,\n",
    "\t\t\"web_search_needed\": web_search_needed,\n",
    "\t\t\"use_sql\": use_sql\n",
    "\t}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rewrite query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_query(state):\n",
    "    \"\"\"\n",
    "    Rewrite the query to produce a better question.\n",
    "    Args:\n",
    "    state (dict): The current graph state\n",
    "    Returns:\n",
    "    state (dict): Updates question key with a re-phrased or re-written question\n",
    "    \"\"\"\n",
    "    print(\"---REWRITE QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    # Re-write question\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"documents\": documents, \"question\": better_question}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based on the re-written question.\n",
    "    Args:\n",
    "    state (dict): The current graph state\n",
    "    Returns:\n",
    "    state (dict): Updates documents key with appended web results\n",
    "    \"\"\"\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Web search\n",
    "    docs = tv_search.invoke(question)\n",
    "    \n",
    "    # G·ª° l·ªói: ki·ªÉm tra c·∫•u tr√∫c tr·∫£ v·ªÅ\n",
    "    print(\"DOCS TYPE:\", type(docs))\n",
    "    print(\"FIRST ELEMENT TYPE:\", type(docs[0]) if docs else \"EMPTY\")\n",
    "\n",
    "    # N·∫øu docs l√† list of strings\n",
    "    if isinstance(docs[0], str):\n",
    "        web_content = \"\\n\\n\".join(docs)\n",
    "    # N·∫øu docs l√† list of dicts\n",
    "    elif isinstance(docs[0], dict) and \"content\" in docs[0]:\n",
    "        web_content = \"\\n\\n\".join([d[\"content\"] for d in docs])\n",
    "    # N·∫øu docs l√† list of Document\n",
    "    elif isinstance(docs[0], Document):\n",
    "        web_content = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "    else:\n",
    "        raise TypeError(\"Unsupported doc format\")\n",
    "\n",
    "    web_results = Document(page_content=web_content)\n",
    "    documents.append(web_results)\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "import pandas as pd\n",
    "\n",
    "def query_sql(state):\n",
    "    print(\"---EXECUTE RAW SQL QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # K·∫øt n·ªëi ƒë·∫øn DB\n",
    "    conn = connect_to_database()\n",
    "    if conn is None:\n",
    "        raise ValueError(\"Kh√¥ng th·ªÉ k·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu.\")\n",
    "\n",
    "    # Sinh c√¢u truy v·∫•n SQL\n",
    "    schema_info = get_schema_and_samples(conn)\n",
    "    sql_query = generate_sql_query(question, schema_info)\n",
    "    if not sql_query:\n",
    "        conn.close()\n",
    "        raise ValueError(\"Kh√¥ng th·ªÉ sinh truy v·∫•n SQL t·ª´ c√¢u h·ªèi.\")\n",
    "\n",
    "    # Th·ª±c thi\n",
    "    results = execute_sql_query(conn, sql_query)\n",
    "    conn.close()\n",
    "\n",
    "    # ‚úÖ X·ª≠ l√Ω k·∫øt qu·∫£\n",
    "    if results is None or results.empty:\n",
    "        content = \"‚ö†Ô∏è Kh√¥ng c√≥ k·∫øt qu·∫£ t·ª´ truy v·∫•n SQL.\"\n",
    "    else:\n",
    "        content = (\n",
    "            f\"üìä K·∫øt qu·∫£ t·ª´ truy v·∫•n SQL:\\n\\n{results.to_markdown(index=False)}\"\n",
    "        )\n",
    "\n",
    "    # ‚úÖ G·∫Øn v√†o document v√† l∆∞u l·∫°i SQL truy v·∫•n n·∫øu c·∫ßn\n",
    "    doc = Document(page_content=content)\n",
    "    return {\n",
    "        \"documents\": state[\"documents\"] + [doc],\n",
    "        \"question\": question,\n",
    "        \"sql_query\": sql_query  # ‚¨ÖÔ∏è t√πy ch·ªçn: n·∫øu mu·ªën d√πng l·∫°i sau\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state):\n",
    "    print(\"---GENERATE ANSWER---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    # RAG generation\n",
    "    generation = qa_rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question,\"generation\": generation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute FA and TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "from langchain.schema import Document\n",
    "from finance_metrics import load_formulas, identify_metric, get_required_fields, compute_metric\n",
    "from plot_metric import plot_metric\n",
    "import pandas as pd\n",
    "\n",
    "# --- Node: compute_fa ---\n",
    "def compute_fa(state):\n",
    "    question = state[\"question\"]\n",
    "    conn = connect_to_database()\n",
    "    metadata = load_formulas()\n",
    "    _, metric_name = identify_metric(question, metadata)\n",
    "    required_fields = get_required_fields(\"FA\", metric_name, metadata)\n",
    "\n",
    "    query = f\"SELECT {', '.join(required_fields)} FROM djia_companies WHERE symbol = 'AAPL' LIMIT 1;\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "\n",
    "    if df.empty:\n",
    "        result_str = f\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ t√≠nh {metric_name}.\"\n",
    "    else:\n",
    "        result = compute_metric(metric_name, df.iloc[0].to_dict())\n",
    "        result_str = f\"{metric_name} = {result}\"\n",
    "\n",
    "    return {\n",
    "        \"documents\": state[\"documents\"] + [Document(page_content=result_str)],\n",
    "        \"question\": question\n",
    "    }\n",
    "\n",
    "def compute_ta(state):\n",
    "    question = state[\"question\"]\n",
    "    conn = connect_to_database()\n",
    "    metadata = load_formulas()\n",
    "    _, metric_name = identify_metric(question, metadata)\n",
    "\n",
    "    df = pd.read_sql('SELECT \"Date\", \"Close\" FROM djia_prices WHERE \"Ticker\" = \\'AAPL\\' ORDER BY \"Date\" ASC LIMIT 100', conn)\n",
    "    conn.close()\n",
    "    df.rename(columns={\"Date\": \"date\", \"Close\": \"price\"}, inplace=True)\n",
    "\n",
    "    image_base64 = plot_metric(metric_name, df)\n",
    "    result_doc = Document(\n",
    "        page_content=f\"Bi·ªÉu ƒë·ªì {metric_name} cho AAPL:\",\n",
    "        metadata={\"image_base64\": image_base64}\n",
    "    )\n",
    "    return {\n",
    "        \"documents\": state[\"documents\"] + [result_doc],\n",
    "        \"question\": question\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_branch(state):\n",
    "    question = state[\"question\"].lower()\n",
    "    metadata = load_formulas()\n",
    "    _, metric = identify_metric(question, metadata)\n",
    "\n",
    "    if metric in [\"RSI\", \"MACD\", \"MA\", \"BollingerBands\"]:\n",
    "        return \"compute_ta\"\n",
    "    elif metric in [\"EPS\", \"PE\", \"ROE\", \"DebtRatio\"]:\n",
    "        return \"compute_fa\"\n",
    "\n",
    "    try:\n",
    "        schema_info = get_schema_and_samples(connect_to_database())\n",
    "        sql_query = generate_sql_query(question, schema_info)\n",
    "        if sql_query:\n",
    "            return \"query_sql\"\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return \"rewrite_query\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Agent Graph with LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Build the agent graph ---\n",
    "agentic_rag = StateGraph(GraphState)\n",
    "\n",
    "# Add nodes\n",
    "agentic_rag.add_node(\"retrieve\", retrieve)\n",
    "agentic_rag.add_node(\"grade_documents\", grade_documents)\n",
    "agentic_rag.add_node(\"rewrite_query\", rewrite_query)\n",
    "agentic_rag.add_node(\"web_search\", web_search)\n",
    "agentic_rag.add_node(\"query_sql\", query_sql)\n",
    "agentic_rag.add_node(\"compute_ta\", compute_ta)\n",
    "agentic_rag.add_node(\"compute_fa\", compute_fa)\n",
    "agentic_rag.add_node(\"generate_answer\", generate_answer)\n",
    "\n",
    "# Set flow\n",
    "agentic_rag.set_entry_point(\"retrieve\")\n",
    "agentic_rag.add_edge(\"retrieve\", \"grade_documents\")\n",
    "\n",
    "agentic_rag.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_branch,\n",
    "    {\n",
    "        \"compute_ta\": \"compute_ta\",\n",
    "        \"compute_fa\": \"compute_fa\",\n",
    "        \"query_sql\": \"query_sql\",\n",
    "        \"rewrite_query\": \"rewrite_query\"\n",
    "    }\n",
    ")\n",
    "\n",
    "agentic_rag.add_edge(\"rewrite_query\", \"web_search\")\n",
    "agentic_rag.add_edge(\"web_search\", \"generate_answer\")\n",
    "agentic_rag.add_edge(\"query_sql\", \"generate_answer\")\n",
    "agentic_rag.add_edge(\"compute_fa\", \"generate_answer\")\n",
    "agentic_rag.add_edge(\"compute_ta\", \"generate_answer\")\n",
    "agentic_rag.add_edge(\"generate_answer\", END)\n",
    "\n",
    "# Compile\n",
    "agentic_rag = agentic_rag.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display, Markdown\n",
    "# display(Image(agentic_rag.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Agentic RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVAL FROM VECTOR DB---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "K·∫øt n·ªëi th√†nh c√¥ng ƒë·∫øn PostgreSQL.\n",
      "---EXECUTE RAW SQL QUERY---\n",
      "K·∫øt n·ªëi th√†nh c√¥ng ƒë·∫øn PostgreSQL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trung\\AppData\\Local\\Temp\\ipykernel_8812\\2340806628.py:99: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---GENERATE ANSWER---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The companies in the DJIA with a P/E ratio greater than 25 are:\n",
       "\n",
       "1. Apple Inc. ‚Äì 33.219  \n",
       "2. Amgen Inc. ‚Äì 37.1974  \n",
       "3. Salesforce, Inc. ‚Äì 42.1811  \n",
       "4. Walt Disney Company (The) ‚Äì 29.3117  \n",
       "5. Dow Inc. ‚Äì 75.05  \n",
       "6. International Business Machines ‚Äì 39.6604  \n",
       "7. Coca-Cola Company (The) ‚Äì 29.2317  \n",
       "8. McDonald's Corporation ‚Äì 27.7842  \n",
       "9. Microsoft Corporation ‚Äì 31.5499  \n",
       "10. Procter & Gamble Company (The) ‚Äì 25.5587  \n",
       "11. Visa Inc. ‚Äì 33.7873  \n",
       "12. Walmart Inc. ‚Äì 39.4564  \n",
       "\n",
       "These 12 companies all have P/E ratios exceeding 25 according to the provided data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Which companies in the DJIA have a P/E ratio greater than 25?\"\n",
    "response = agentic_rag.invoke({\"question\": query})\n",
    "display(Markdown(response['generation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVAL FROM VECTOR DB---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\HK2_2024_2025\\Data Platform\\Thuc_hanh\\CK\\venv\\lib\\site-packages\\langchain_core\\vectorstores\\base.py:1082: UserWarning: Relevance scores must be between 0 and 1, got [(Document(id='ca714764-8a25-4be5-b5a1-90fe0d048889', metadata={'name': 'Dow Inc.', 'sector': 'Basic Materials', 'symbol': 'DOW'}, page_content='Dow Inc., through its subsidiaries, provides various materials science solutions for packaging, infrastructure, mobility, and consumer applications in the United States, Canada, Europe, the Middle East, Africa, India, the Asia Pacific, and Latin America. The company operates through Packaging & Specialty Plastics, Industrial Intermediates & Infrastructure, and Performance Materials & Coatings segments. The Packaging & Specialty Plastics segment provides ethylene, propylene, polyethylene, and aromatics products; and other ethylene derivatives, such as polyolefin elastomers, ethylene vinyl acetate, and ethylene propylene diene monomer rubber. The Industrial Intermediates & Infrastructure segment offers polyurethanes, including propylene oxide, propylene glycol, and polyether polyols; aromatic isocyanates and fully formulated polyurethane systems; and chlor-alkali and vinyl comprising chlorine and caustic soda, ethylene dichloride, and vinyl chloride monomer; and construction chemicals'), -0.06640057254700493), (Document(id='a23fea29-5b70-4fe7-b2eb-2b7fde78f356', metadata={'name': 'Dow Inc.', 'sector': 'Basic Materials', 'symbol': 'DOW'}, page_content='Dow Inc., through its subsidiaries, provides various materials science solutions for packaging, infrastructure, mobility, and consumer applications in the United States, Canada, Europe, the Middle East, Africa, India, the Asia Pacific, and Latin America. The company operates through Packaging & Specialty Plastics, Industrial Intermediates & Infrastructure, and Performance Materials & Coatings segments. The Packaging & Specialty Plastics segment provides ethylene, propylene, polyethylene, and aromatics products; and other ethylene derivatives, such as polyolefin elastomers, ethylene vinyl acetate, and ethylene propylene diene monomer rubber. The Industrial Intermediates & Infrastructure segment offers polyurethanes, including propylene oxide, propylene glycol, and polyether polyols; aromatic isocyanates and fully formulated polyurethane systems; and chlor-alkali and vinyl comprising chlorine and caustic soda, ethylene dichloride, and vinyl chloride monomer; and construction chemicals'), -0.06660624916773816), (Document(id='529cbda8-b663-463e-a98b-4557b2414b36', metadata={'name': 'Dow Inc.', 'sector': 'Basic Materials', 'symbol': 'DOW'}, page_content='Dow Inc., through its subsidiaries, provides various materials science solutions for packaging, infrastructure, mobility, and consumer applications in the United States, Canada, Europe, the Middle East, Africa, India, the Asia Pacific, and Latin America. The company operates through Packaging & Specialty Plastics, Industrial Intermediates & Infrastructure, and Performance Materials & Coatings segments. The Packaging & Specialty Plastics segment provides ethylene, propylene, polyethylene, and aromatics products; and other ethylene derivatives, such as polyolefin elastomers, ethylene vinyl acetate, and ethylene propylene diene monomer rubber. The Industrial Intermediates & Infrastructure segment offers polyurethanes, including propylene oxide, propylene glycol, and polyether polyols; aromatic isocyanates and fully formulated polyurethane systems; and chlor-alkali and vinyl comprising chlorine and caustic soda, ethylene dichloride, and vinyl chloride monomer; and construction chemicals'), -0.0666549709246167)]\n",
      "  self.vectorstore.similarity_search_with_relevance_scores(\n",
      "No relevant docs were retrieved using the relevance score threshold 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "K·∫øt n·ªëi th√†nh c√¥ng ƒë·∫øn PostgreSQL.\n",
      "---EXECUTE RAW SQL QUERY---\n",
      "K·∫øt n·ªëi th√†nh c√¥ng ƒë·∫øn PostgreSQL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trung\\AppData\\Local\\Temp\\ipykernel_8812\\2340806628.py:99: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---GENERATE ANSWER---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The companies whose average closing price in the last 90 days is above 200 and have a P/E ratio lower than 20 are:\n",
       "\n",
       "1. American Express Company (P/E ratio: 18.4794, Average price: 272.124)\n",
       "2. Caterpillar, Inc. (P/E ratio: 13.8917, Average price: 325.144)\n",
       "3. Goldman Sachs Group, Inc. (The) (P/E ratio: 12.6418, Average price: 561.486)\n",
       "4. JP Morgan Chase & Co. (P/E ratio: 11.9446, Average price: 244.071)\n",
       "5. The Travelers Companies, Inc. (P/E ratio: 14.1078, Average price: 252.963)\n",
       "6. UnitedHealth Group Incorporated (P/E ratio: 17.5163, Average price: 502.834)\n",
       "\n",
       "All these companies meet both criteria of having an average closing price above 200 and a P/E ratio below 20."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"List companies whose average closing price in the last 90 days is above 200 and have a P/E ratio lower than 20.\"\n",
    "response = agentic_rag.invoke({\"question\": query})\n",
    "display(Markdown(response['generation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. C√¢u h·ªèi t·∫≠p trung v√†o ch·ªâ s·ªë t√†i ch√≠nh (EPS, P/E, dividend, market cap):\n",
    "- Which companies in the DJIA have a P/E ratio greater than 25?\n",
    "\n",
    "- List the top 5 companies with the highest market capitalization and show their dividend yield and P/E ratio.\n",
    "\n",
    "- What is the average P/E ratio of companies in the Technology sector?\n",
    "\n",
    "- Show all companies with a dividend yield greater than 3% and market cap over 500 billion USD.\n",
    "\n",
    "- Find all companies where the P/E ratio is less than the average P/E ratio across all DJIA companies.\n",
    "\n",
    "2. C√¢u h·ªèi k·∫øt h·ª£p djia_prices + djia_companies (g·ª£i √Ω v·ªÅ EPS qua Close):\n",
    "- Calculate the average closing price of Apple (AAPL) over the past 30 days.\n",
    "\n",
    "- For each company, calculate the maximum daily trading volume in the last 6 months.\n",
    "\n",
    "- List companies whose average closing price in the last 90 days is above 200 and have a P/E ratio lower than 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
