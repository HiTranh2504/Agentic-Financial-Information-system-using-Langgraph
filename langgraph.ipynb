{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start LangGraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain==0.2.0\n",
    "# !pip install langchain-openai==0.1.7\n",
    "# !pip install langchain-community==0.2.0\n",
    "# !pip install langgraph==0.1.1\n",
    "# !pip install langchain-chroma==0.1.1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use file .env to get the API key\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_KEY\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Vector Database for Wikipedia Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open AI Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "openai_embed_model = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Chunk Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'Basil', 'article_id': '73985'}, page_content='Basil (\"Ocimum basilicum\") ( or ) is a plant of the Family Lamiaceae. It is also known as Sweet Basil or Tulsi. It is a tender low-growing herb that is grown as a perennial in warm, tropical climates. Basil is originally native to India and other tropical regions of Asia. It has been cultivated there for more than 5,000 years. It is prominently featured in many cuisines throughout the world. Some of them are Italian, Thai, Vietnamese and Laotian cuisines. It grows to between 30–60\\xa0cm tall. It has light green, silky leaves 3–5\\xa0cm long and 1–3\\xa0cm broad. The leaves are opposite each other. The flowers are quite big. They are white in color and arranged as a spike. The plant tastes somewhat like anise, with a strong, pungent, sweet smell. Basil is very sensitive to cold. It is best grown in hot, dry conditions. While most common varieties are treated as annuals, some are perennial, including African Blue and Holy Thai basil. The word \"basil\" comes from the Greek βασιλεύς (\"basileus\"), meaning \"royal\". This is because it is believed to have grown above the spot where St. Constantine and Helen discovered the Holy Cross. The \"Oxford English Dictionary\" quotes speculations that basil may have been used in \"some royal unguent, bath, or medicine\". Basil is still considered the \"king of herbs\" by many cookery authors. An alternative etymology has \"basil\" coming from the Latin word \"basilicus\", meaning dragon and being the root for basilisk, but this likely was a linguistic reworking of the word as brought from Greece.'),\n",
       " Document(metadata={'title': 'Roerich’s Pact', 'article_id': '259745'}, page_content='The Roerich Pact is a treaty on Protection of Artistic and Scientific Institutions and Historic Monuments, signed by the representatives of 21 states in the Oval Office of the White House on 15 April 1935. As of January 1, 1990, the Roerich Pact had been ratified by ten nations: Brazil, Chile, Colombia, Cuba, the Dominican Republic, El Salvador, Guatemala, Mexico, the United States, and Venezuela. It went into effect on 26 August 1935. The Government of India approved the Treaty in 1948, but did not take any further formal action. The Roerich Pact is also known as \"Pax Cultura\" (\"Cultural Peace\" or \"Peace through Culture\"). The most important part of the Roerich Pact is the legal recognition that the protection of culture is always more important than any military necessity. Russian painter and philosopher Nicholas Roerich (1874-1947) started the modern movement for the defense of cultural objects, in order for a “Peace of Civilizations”. Nicholas Roerich was born on October 9, 1874, in St. Petersburg. He became a successful painter. One of his paintings was purchased by Nicholas II of Russia.'),\n",
       " Document(metadata={'title': 'Nico Hülkenberg', 'article_id': '260252'}, page_content='Nicolas \"Nico\" Hülkenberg (born 19 August 1987 in Emmerich am Rhein, North Rhine-Westphalia) is a German racing driver. He races in Formula One for Williams. He won the 2009 GP2 Series championship. He is a past champion in Formula Three Euroseries and the A1 Grand Prix, as part of A1 Team Germany. He is one of three drivers to win the GP2 series championship in his first season. The other two are Lewis Hamilton and Nico Rosberg. Hülkenberg earned his first pole position at the Brazilian Grand Prix. His lap time was over one second faster than second place Sebastian Vettel on a drying circuit. It was the first pole for Williams in 100 races, since the European Grand Prix. After the Abu Dhabi GP, it was announced that Hülkenberg would not race for Williams in 2011. For the season, he is the third driver for the Force India team.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "wikipedia_filepath = './data/simplewiki-2020-11-01.jsonl.gz'\n",
    "docs = []\n",
    "with gzip.open(wikipedia_filepath, 'rt', encoding='utf8') as fIn:\n",
    "    for line in fIn:\n",
    "        data = json.loads(line.strip())\n",
    "        # Add documents\n",
    "        docs.append({\n",
    "            'metadata': {\n",
    "                'title': data.get('title'),\n",
    "                'article_id': data.get('id')\n",
    "            },\n",
    "            'data': ' '.join(data.get('paragraphs')[0:3])  # restrict data to first 3 paragraphs to run later modules faster\n",
    "            })\n",
    "docs = [doc for doc in docs for x in ['india'] if x in doc['data'].lower().split()]\n",
    "docs = [Document(page_content=doc['data'], metadata=doc['metadata']) for doc in docs]\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=300)\n",
    "chunked_docs = splitter.split_documents(docs)\n",
    "chunked_docs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Vector DB and Persist on the Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "chroma_db = Chroma.from_documents(documents=chunked_docs, collection_name='rag_wikipedia_db',embedding=openai_embed_model, collection_metadata={\"hnsw:space\": \"cosine\"}, persist_directory=\"./wikipedia_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup a Vector Database Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='44b3bb5a-56e2-4249-8fac-fa774d3bb59c', metadata={'article_id': '5117', 'title': 'New Delhi'}, page_content='New Delhi () is the capital of India and a union territory of the megacity of Delhi. It has a very old history and is home to several monuments where the city is expensive to live in. In traditional Indian geography it falls under the North Indian zone. The city has an area of about 42.7\\xa0km. New Delhi has a population of about 9.4 Million people.'),\n",
       " Document(id='eb56ab47-4627-4cf9-80bd-7bde427ede7f', metadata={'article_id': '5117', 'title': 'New Delhi'}, page_content='New Delhi () is the capital of India and a union territory of the megacity of Delhi. It has a very old history and is home to several monuments where the city is expensive to live in. In traditional Indian geography it falls under the North Indian zone. The city has an area of about 42.7\\xa0km. New Delhi has a population of about 9.4 Million people.'),\n",
       " Document(id='8cb8776c-ce5a-46fd-bd4d-64e97a6b63fc', metadata={'article_id': '5117', 'title': 'New Delhi'}, page_content='New Delhi () is the capital of India and a union territory of the megacity of Delhi. It has a very old history and is home to several monuments where the city is expensive to live in. In traditional Indian geography it falls under the North Indian zone. The city has an area of about 42.7\\xa0km. New Delhi has a population of about 9.4 Million people.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_threshold_retriever = chroma_db.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"k\": 3, \"score_threshold\": 0.3})\n",
    "# We can then test if our retriever is working on some sample queries.\n",
    "query = \"what is the capital of India?\"\n",
    "top3_docs = similarity_threshold_retriever.invoke(query)\n",
    "top3_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what is langgraph?\"\n",
    "top3_docs = similarity_threshold_retriever.invoke(query)\n",
    "top3_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Query Retrieval Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Tạo LLM với cấu hình Pydantic V2\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# Parser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Prompt system\n",
    "SYS_PROMPT = \"\"\"\n",
    "You are an expert grader assessing relevance of a retrieved document to a user question.\n",
    "Answer only 'yes' or 'no' depending on whether the document is relevant to the question.\n",
    "\"\"\"\n",
    "\n",
    "# Tạo prompt template\n",
    "grade_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", SYS_PROMPT),\n",
    "    (\"human\", \"Retrieved document:\\n{document}\\n\\nUser question:\\n{question}\")\n",
    "])\n",
    "\n",
    "# Tạo chain xử lý\n",
    "doc_grader = grade_prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Delhi () is the capital of India and a union territory of the megacity of Delhi. It has a very old history and is home to several monuments where the city is expensive to live in. In traditional Indian geography it falls under the North Indian zone. The city has an area of about 42.7 km. New Delhi has a population of about 9.4 Million people.\n",
      "GRADE: yes\n",
      "\n",
      "New Delhi () is the capital of India and a union territory of the megacity of Delhi. It has a very old history and is home to several monuments where the city is expensive to live in. In traditional Indian geography it falls under the North Indian zone. The city has an area of about 42.7 km. New Delhi has a population of about 9.4 Million people.\n",
      "GRADE: yes\n",
      "\n",
      "New Delhi () is the capital of India and a union territory of the megacity of Delhi. It has a very old history and is home to several monuments where the city is expensive to live in. In traditional Indian geography it falls under the North Indian zone. The city has an area of about 42.7 km. New Delhi has a population of about 9.4 Million people.\n",
      "GRADE: yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"what is the capital of India?\"\n",
    "top3_docs = similarity_threshold_retriever.invoke(query)\n",
    "for doc in top3_docs:\n",
    "\tprint(doc.page_content)\n",
    "\tprint('GRADE:', doc_grader.invoke({\n",
    "\t\t\"question\": query,\n",
    "\t\t\"document\": doc.page_content\n",
    "\t}))\n",
    "\tprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a QA RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "\n",
    "# Create RAG prompt for response generation\n",
    "prompt = \"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If no context is present or if you don't know the answer, just say that you don't know the answer.\n",
    "Do not make up the answer unless it is there in the provided context.\n",
    "Give a detailed answer and to the point answer with regard to the question.\n",
    "Question:\n",
    "{question}\n",
    "Context:\n",
    "{context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(prompt)\n",
    "\n",
    "# Initialize connection with gpt-4.1-mini\n",
    "chatgpt = ChatOpenAI(model_name='gpt-4.1-mini', temperature=0)\n",
    "\n",
    "# Used for separating context docs with new lines\n",
    "def format_docs(docs):\n",
    "\treturn \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Create QA RAG chain\n",
    "qa_rag_chain = (\n",
    "\t{\n",
    "\t\t\"context\": (itemgetter('context')\n",
    "\t\t\t\t\t|\n",
    "\t\t\t\t\tRunnableLambda(format_docs)),\n",
    "\t\t\"question\": itemgetter('question')\n",
    "\t}\n",
    "\t|\n",
    "\tprompt_template\n",
    "\t|\n",
    "\tchatgpt\n",
    "\t|\n",
    "\tStrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is New Delhi. It is a union territory within the megacity of Delhi and is located in the North Indian zone according to traditional Indian geography. New Delhi has a rich history, is home to several monuments, and covers an area of about 42.7 square kilometers. The city has a population of approximately 9.4 million people.\n"
     ]
    }
   ],
   "source": [
    "query = \"what is the capital of India?\"\n",
    "top3_docs = similarity_threshold_retriever.invoke(query)\n",
    "result = qa_rag_chain.invoke({\"context\": top3_docs, \"question\": query})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided context does not contain any information about the winner of the Champions League in 2024. Therefore, I do not know the answer to who won the Champions League in 2024 based on the given information.\n"
     ]
    }
   ],
   "source": [
    "query = \"who won the champions league in 2024?\"\n",
    "top3_docs = similarity_threshold_retriever.invoke(query)\n",
    "result = qa_rag_chain.invoke({\"context\": top3_docs, \"question\": query})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Query Rephraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM for question rewriting\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "# Prompt template for rewriting\n",
    "SYS_PROMPT = \"\"\"Act as a question re-writer and perform the following task:\n",
    "\t\t\t\t - Convert the following input question to a better version that is optimized for web search.\n",
    "\t\t\t\t - When re-writing, look at the input question and try to reason about the underlying semantic intent / meaning.\n",
    "\t\t\t \"\"\"\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "\t[\n",
    "\t\t(\"system\", SYS_PROMPT),\n",
    "\t\t(\"human\", \"\"\"Here is the initial question:\n",
    "\t\t\t\t\t {question}\n",
    "\t\t\t\t\t Formulate an improved question.\n",
    "\t\t\t\t  \"\"\")\n",
    "\t]\n",
    ")\n",
    "\n",
    "# Create rephraser chain\n",
    "question_rewriter = (re_write_prompt|llm|StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who was the winner of the 2024 UEFA Champions League?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"who won the champions league in 2024?\"\n",
    "question_rewriter.invoke({\"question\": query})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Web Search Tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tv_search = TavilySearchResults(max_results=3, search_depth='advanced', max_tokens=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB Config: {'dbname': 'postgres', 'user': 'postgres.gmzvpcfwyvluwfwiyqsy', 'password': '6orAlooo94sTKvpY', 'host': 'aws-0-ap-southeast-1.pooler.supabase.com', 'port': 5432, 'sslmode': 'require'}\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": os.getenv(\"DBNAME\") or os.getenv(\"POSTGRES_DB\"),\n",
    "    \"user\": os.getenv(\"DBUSER\") or os.getenv(\"POSTGRES_USER\"),\n",
    "    \"password\": os.getenv(\"DBPASSWORD\") or os.getenv(\"POSTGRES_PASSWORD\"),\n",
    "    \"host\": os.getenv(\"DBHOST\") or \"localhost\",\n",
    "    \"port\": int(os.getenv(\"DBPORT\", 5432)),\n",
    "    \"sslmode\": os.getenv(\"SSL_MODE\", \"require\")\n",
    "}\n",
    "\n",
    "\n",
    "print(f\"DB Config: {DB_CONFIG}\")\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def connect_to_database():\n",
    "    try:\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        print(\"Kết nối thành công đến PostgreSQL.\")\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi kết nối cơ sở dữ liệu: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_schema_and_samples(conn):\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT table_name FROM information_schema.tables WHERE table_schema='public';\")\n",
    "        tables = cursor.fetchall()\n",
    "        schema_info = {}\n",
    "        for (table,) in tables:\n",
    "            cursor.execute(f\"SELECT column_name, data_type FROM information_schema.columns WHERE table_name = '{table}';\")\n",
    "            schema_info[table] = [{\"column_name\": col, \"data_type\": dtype} for col, dtype in cursor.fetchall()]\n",
    "            cursor.execute(f\"SELECT * FROM {table} LIMIT 3;\")\n",
    "            sample_rows = cursor.fetchall()\n",
    "            colnames = [desc[0] for desc in cursor.description]\n",
    "            schema_info[f\"{table}_samples\"] = [dict(zip(colnames, row)) for row in sample_rows]\n",
    "        cursor.close()\n",
    "        return schema_info\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def load_metadata():\n",
    "    try:\n",
    "        with open(\"metadata.yml\", \"r\") as file:\n",
    "            return yaml.safe_load(file)\n",
    "    except FileNotFoundError:\n",
    "        return {}\n",
    "\n",
    "def generate_sql_query(user_question, schema_info=None):\n",
    "    prompt = f\"\"\"\n",
    "You are a PostgreSQL expert working with a single table called `stocks`.\n",
    "\n",
    "This table contains daily stock information with the following columns:\n",
    "\n",
    "- date: Date of the record (format: YYYY-MM-DD)\n",
    "- price: The closing price of the stock on that date (FLOAT)\n",
    "- open: The opening price of the stock on that date (FLOAT)\n",
    "- high: The highest price of the stock on that date (FLOAT)\n",
    "- low: The lowest price of the stock on that date (FLOAT)\n",
    "- volume: Trading volume (format: float + 'M' suffix for millions)\n",
    "- change_percent: Daily percentage change in stock price (can be positive or negative)\n",
    "\n",
    "Assume this table is already in a PostgreSQL database as `stocks`.\n",
    "\n",
    "User Question:\n",
    "{user_question}\n",
    "\n",
    "Write a correct and optimized PostgreSQL query to answer this question. \n",
    "Do not explain or wrap the query in markdown. Just return raw SQL.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        sql_query = response.choices[0].message.content\n",
    "        sql_query = re.sub(r'^```sql', '', sql_query).strip('` \\n')\n",
    "        return sql_query\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi sinh SQL: {e}\")\n",
    "        return None\n",
    "\n",
    "def execute_sql_query(conn, query):\n",
    "    try:\n",
    "        df = pd.read_sql(query, conn)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi thực thi SQL: {e}\")\n",
    "        return None\n",
    "    \n",
    "def run_chat(question: str):\n",
    "    conn = connect_to_database()\n",
    "    if conn is None:\n",
    "        return\n",
    "\n",
    "    schema_info = get_schema_and_samples(conn)\n",
    "    sql_query = generate_sql_query(question, schema_info)\n",
    "\n",
    "    if not sql_query:\n",
    "        print(\"Không thể sinh truy vấn SQL.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nSQL sinh ra:\\n{sql_query}\")\n",
    "    results = execute_sql_query(conn, sql_query)\n",
    "\n",
    "    if results is None:\n",
    "        print(\"Truy vấn lỗi.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nDữ liệu:\")\n",
    "    print(results.head(5))\n",
    "\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Agentic RAG components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search_needed: str\n",
    "    documents: List[str]\n",
    "documents: List[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve function for retrieval from Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "\tprint(\"---RETRIEVAL FROM VECTOR DB---\")\n",
    "\tquestion = state[\"question\"]\n",
    "\t# Retrieval\n",
    "\tdocuments = similarity_threshold_retriever.invoke(question)\n",
    "\treturn {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grade documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state):\n",
    "\tprint(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "\tquestion = state[\"question\"]\n",
    "\tdocuments = state[\"documents\"]\n",
    "\n",
    "\tfiltered_docs = []\n",
    "\tweb_search_needed = \"No\"\n",
    "\tuse_sql = \"No\"\n",
    "\n",
    "\tif documents:\n",
    "\t\tfor d in documents:\n",
    "\t\t\tscore = doc_grader.invoke(\n",
    "\t\t\t\t{\"question\": question, \"document\": d.page_content}\n",
    "\t\t\t)\n",
    "\t\t\tgrade = score.strip().lower()\n",
    "\n",
    "\t\t\tif grade == \"yes\":\n",
    "\t\t\t\tprint(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "\t\t\t\tfiltered_docs.append(d)\n",
    "\t\t\telse:\n",
    "\t\t\t\t# Phân loại theo nội dung\n",
    "\t\t\t\tif \"database\" in question.lower() or \"truy vấn\" in question.lower() or \"from table\" in question.lower():\n",
    "\t\t\t\t\tuse_sql = \"Yes\"\n",
    "\t\t\t\t\tprint(\"---GRADE: DOCUMENT NOT RELEVANT, SUGGEST SQL---\")\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tweb_search_needed = \"Yes\"\n",
    "\t\t\t\t\tprint(\"---GRADE: DOCUMENT NOT RELEVANT, SUGGEST WEB SEARCH---\")\n",
    "\telse:\n",
    "\t\t# Kiểm tra nội dung câu hỏi → có chứa từ khóa SQL\n",
    "\t\tif \"database\" in question.lower() or \"truy vấn\" in question.lower() or \"from table\" in question.lower():\n",
    "\t\t\tuse_sql = \"Yes\"\n",
    "\t\t\tprint(\"---NO DOCS, BUT QUESTION SUGGESTS SQL---\")\n",
    "\t\telse:\n",
    "\t\t\tweb_search_needed = \"Yes\"\n",
    "\n",
    "\treturn {\n",
    "\t\t\"documents\": filtered_docs,\n",
    "\t\t\"question\": question,\n",
    "\t\t\"web_search_needed\": web_search_needed,\n",
    "\t\t\"use_sql\": use_sql\n",
    "\t}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rewrite query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_query(state):\n",
    "    \"\"\"\n",
    "    Rewrite the query to produce a better question.\n",
    "    Args:\n",
    "    state (dict): The current graph state\n",
    "    Returns:\n",
    "    state (dict): Updates question key with a re-phrased or re-written question\n",
    "    \"\"\"\n",
    "    print(\"---REWRITE QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    # Re-write question\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"documents\": documents, \"question\": better_question}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based on the re-written question.\n",
    "    Args:\n",
    "    state (dict): The current graph state\n",
    "    Returns:\n",
    "    state (dict): Updates documents key with appended web results\n",
    "    \"\"\"\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Web search\n",
    "    docs = tv_search.invoke(question)\n",
    "    \n",
    "    # Gỡ lỗi: kiểm tra cấu trúc trả về\n",
    "    print(\"DOCS TYPE:\", type(docs))\n",
    "    print(\"FIRST ELEMENT TYPE:\", type(docs[0]) if docs else \"EMPTY\")\n",
    "\n",
    "    # Nếu docs là list of strings\n",
    "    if isinstance(docs[0], str):\n",
    "        web_content = \"\\n\\n\".join(docs)\n",
    "    # Nếu docs là list of dicts\n",
    "    elif isinstance(docs[0], dict) and \"content\" in docs[0]:\n",
    "        web_content = \"\\n\\n\".join([d[\"content\"] for d in docs])\n",
    "    # Nếu docs là list of Document\n",
    "    elif isinstance(docs[0], Document):\n",
    "        web_content = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "    else:\n",
    "        raise TypeError(\"Unsupported doc format\")\n",
    "\n",
    "    web_results = Document(page_content=web_content)\n",
    "    documents.append(web_results)\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'd:\\HK2_2024_2025\\Data Platform\\Thuc_hanh\\CK\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfinance_metrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_formulas, identify_metric, get_required_fields, compute_metric\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplot_metric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_metric\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n",
      "File \u001b[1;32md:\\HK2_2024_2025\\Data Platform\\Thuc_hanh\\CK\\chatbot-finacial-langgraph\\plot_metric.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbase64\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BytesIO\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "from finance_metrics import load_formulas, identify_metric, get_required_fields, compute_metric\n",
    "from plot_metric import plot_metric\n",
    "from langchain.schema import Document\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def query_sql(state):\n",
    "    print(\"---EXECUTE SQL QUERY OR METRIC COMPUTATION---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Kết nối đến cơ sở dữ liệu\n",
    "    conn = connect_to_database()\n",
    "    if conn is None:\n",
    "        raise ValueError(\"Không thể kết nối cơ sở dữ liệu.\")\n",
    "\n",
    "    schema_info = get_schema_and_samples(conn)\n",
    "    metadata = load_formulas()\n",
    "    category, metric_name = identify_metric(question, metadata)\n",
    "\n",
    "    # Nếu là câu hỏi về chỉ số tài chính\n",
    "    if metric_name:\n",
    "        print(f\"Phát hiện truy vấn liên quan đến chỉ số: {metric_name}\")\n",
    "        required_fields = get_required_fields(category, metric_name, metadata)\n",
    "\n",
    "        # TA metrics - cần vẽ biểu đồ\n",
    "        if metric_name in [\"RSI\", \"MACD\", \"MA\", \"BollingerBands\"]:\n",
    "            df = pd.read_sql(\"SELECT date, price FROM stocks ORDER BY date ASC LIMIT 100\", conn)\n",
    "            conn.close()\n",
    "\n",
    "            image_base64 = plot_metric(metric_name, df)\n",
    "            result_doc = Document(\n",
    "                page_content=f\"Biểu đồ {metric_name}:\",\n",
    "                metadata={\"image_base64\": image_base64}\n",
    "            )\n",
    "\n",
    "            return {\n",
    "                \"documents\": state[\"documents\"] + [result_doc],\n",
    "                \"question\": question\n",
    "            }\n",
    "\n",
    "        # FA metrics - tính toán dựa trên 1 dòng dữ liệu\n",
    "        else:\n",
    "            field_clause = \", \".join(required_fields)\n",
    "            query = f\"SELECT {field_clause} FROM stocks LIMIT 1;\"\n",
    "            df = pd.read_sql(query, conn)\n",
    "            conn.close()\n",
    "\n",
    "            if df.empty:\n",
    "                result_str = f\"Không tìm thấy đủ dữ liệu để tính {metric_name}.\"\n",
    "            else:\n",
    "                row = df.iloc[0].to_dict()\n",
    "                result = compute_metric(metric_name, row)\n",
    "                result_str = f\"{metric_name} = {result}\"\n",
    "\n",
    "            return {\n",
    "                \"documents\": state[\"documents\"] + [Document(page_content=result_str)],\n",
    "                \"question\": question\n",
    "            }\n",
    "\n",
    "    # Truy vấn SQL thông thường\n",
    "    sql_query = generate_sql_query(question, schema_info)\n",
    "    if not sql_query:\n",
    "        raise ValueError(\"Không thể sinh truy vấn SQL từ câu hỏi.\")\n",
    "\n",
    "    results = execute_sql_query(conn, sql_query)\n",
    "    conn.close()\n",
    "\n",
    "    if results is None or results.empty:\n",
    "        content = \"Không có kết quả từ truy vấn SQL.\"\n",
    "    else:\n",
    "        content = results.to_markdown(index=False)  # hoặc `.to_string(index=False)` nếu không muốn bảng Markdown\n",
    "\n",
    "    # Gán vào document để các bước sau có thể sinh câu trả lời\n",
    "    doc = Document(page_content=content)\n",
    "\n",
    "    # Cập nhật state\n",
    "    return {\n",
    "        \"documents\": state[\"documents\"] + [doc],\n",
    "        \"question\": question\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state):\n",
    "    print(\"---GENERATE ANSWER---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    # RAG generation\n",
    "    generation = qa_rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question,\"generation\": generation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decide to Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state):\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    web_search_needed = state.get(\"web_search_needed\", \"No\")\n",
    "    use_sql = state.get(\"use_sql\", \"No\")\n",
    "\n",
    "    if use_sql == \"Yes\":\n",
    "        print(\"---DECISION: QUERY SQL DATABASE---\")\n",
    "        return \"query_sql\"  # Bạn cần tạo node mới: `query_sql`\n",
    "\n",
    "    elif web_search_needed == \"Yes\":\n",
    "        print(\"---DECISION: WEB SEARCH NEEDED, REWRITE QUERY---\")\n",
    "        return \"rewrite_query\"\n",
    "\n",
    "    else:\n",
    "        print(\"---DECISION: DOCUMENTS ARE RELEVANT, GENERATE ANSWER---\")\n",
    "        return \"generate_answer\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Agent Graph with LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "agentic_rag = StateGraph(GraphState)\n",
    "# Define the nodes\n",
    "agentic_rag.add_node(\"retrieve\", retrieve) # retrieve\n",
    "agentic_rag.add_node(\"grade_documents\", grade_documents) # grade documents\n",
    "agentic_rag.add_node(\"rewrite_query\", rewrite_query) # transform_query\n",
    "agentic_rag.add_node(\"web_search\", web_search) # web search\n",
    "agentic_rag.add_node(\"query_sql\", query_sql) \n",
    "agentic_rag.add_node(\"generate_answer\", generate_answer) # generate answer\n",
    "# Build graph\n",
    "agentic_rag.set_entry_point(\"retrieve\")\n",
    "agentic_rag.add_edge(\"retrieve\", \"grade_documents\")\n",
    "# Quyết định nhánh tiếp theo sau khi chấm điểm tài liệu\n",
    "agentic_rag.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"rewrite_query\": \"rewrite_query\",\n",
    "        \"generate_answer\": \"generate_answer\",\n",
    "        \"query_sql\": \"query_sql\"\n",
    "    }\n",
    ")\n",
    "agentic_rag.add_edge(\"rewrite_query\", \"web_search\")\n",
    "agentic_rag.add_edge(\"web_search\", \"generate_answer\")\n",
    "agentic_rag.add_edge(\"query_sql\", \"generate_answer\")\n",
    "agentic_rag.add_edge(\"generate_answer\", END)\n",
    "# Compile\n",
    "agentic_rag = agentic_rag.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display, Markdown\n",
    "# display(Image(agentic_rag.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Agentic RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVAL FROM VECTOR DB---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: WEB SEARCH NEEDED, REWRITE QUERY---\n",
      "---REWRITE QUERY---\n",
      "---WEB SEARCH---\n",
      "DOCS TYPE: <class 'list'>\n",
      "FIRST ELEMENT TYPE: <class 'dict'>\n",
      "---GENERATE ANSWER---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "For the first quarter of fiscal 2024 (ended December 30, 2023), Apple Inc. reported an earnings per share (EPS) of $2.18. This represented a 16 percent increase year over year. \n",
       "\n",
       "Regarding the price-to-earnings (P/E) ratio for the same period, the forward P/E ratio for 2024 is approximately 28. This forward P/E reflects market expectations based on projected earnings and current stock price around early 2024.\n",
       "\n",
       "**Summary:**\n",
       "- **EPS (Q1 FY 2024):** $2.18  \n",
       "- **Forward P/E ratio (2024):** About 28\n",
       "\n",
       "No specific trailing P/E ratio for the exact quarter was provided, but the forward P/E of 28 is the relevant valuation metric for that period."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Tính EPS và P/E của công ty Apple trong quý 1 năm 2024\"\n",
    "response = agentic_rag.invoke({\"question\": query})\n",
    "display(Markdown(response['generation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVAL FROM VECTOR DB---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: WEB SEARCH NEEDED, REWRITE QUERY---\n",
      "---REWRITE QUERY---\n",
      "---WEB SEARCH---\n",
      "DOCS TYPE: <class 'list'>\n",
      "FIRST ELEMENT TYPE: <class 'dict'>\n",
      "---GENERATE ANSWER---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Để lấy dữ liệu Bollinger Bands của cổ phiếu Apple trong 30 ngày giao dịch gần nhất, bạn cần thực hiện các bước sau:\n",
       "\n",
       "1. **Thu thập dữ liệu giá cổ phiếu Apple trong 30 ngày giao dịch gần nhất**: Bao gồm giá đóng cửa hàng ngày của cổ phiếu AAPL. Dữ liệu này có thể lấy từ các nguồn dữ liệu tài chính như Yahoo Finance, Google Finance, hoặc các nền tảng giao dịch chứng khoán.\n",
       "\n",
       "2. **Tính đường trung bình động (Moving Average - MA)**: Thông thường, Bollinger Bands sử dụng đường trung bình động 20 ngày. Bạn tính MA 20 ngày bằng cách lấy trung bình cộng giá đóng cửa của 20 ngày gần nhất.\n",
       "\n",
       "3. **Tính độ lệch chuẩn (Standard Deviation - SD)**: Tính độ lệch chuẩn của giá đóng cửa trong cùng khoảng thời gian 20 ngày.\n",
       "\n",
       "4. **Tính dải trên và dải dưới của Bollinger Bands**:\n",
       "   - Dải trên = MA 20 ngày + (2 x SD)\n",
       "   - Dải dưới = MA 20 ngày - (2 x SD)\n",
       "\n",
       "5. **Lặp lại tính toán này cho từng ngày trong 30 ngày giao dịch gần nhất** để có được các giá trị Bollinger Bands tương ứng với từng ngày.\n",
       "\n",
       "Tóm lại, bạn cần có dữ liệu giá đóng cửa của Apple trong 30 ngày giao dịch gần nhất, sau đó tính đường trung bình động 20 ngày và độ lệch chuẩn 20 ngày để xác định các dải Bollinger Bands. Các dải này sẽ giúp bạn đánh giá mức độ biến động và các điểm đảo chiều tiềm năng của cổ phiếu Apple trong khoảng thời gian đó.\n",
       "\n",
       "Lưu ý: Trong phần thông tin được cung cấp, chưa có dữ liệu cụ thể về 30 ngày giao dịch gần nhất của Apple, bạn cần truy cập các nguồn dữ liệu tài chính để lấy dữ liệu này và thực hiện tính toán như trên."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Lấy Bollinger Bands của cổ phiếu Apple trong 30 ngày gần nhất.\"\n",
    "response = agentic_rag.invoke({\"question\": query})\n",
    "display(Markdown(response['generation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVAL FROM VECTOR DB---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: DOCUMENTS ARE RELEVANT, GENERATE ANSWER---\n",
      "---GENERATE ANSWER---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The capital of India is New Delhi. It is a union territory within the megacity of Delhi and is located in the North Indian zone according to traditional Indian geography. New Delhi has a rich history, is home to several monuments, and covers an area of about 42.7 square kilometers. The city has a population of approximately 9.4 million people."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"what is the capital of India?\"\n",
    "response = agentic_rag.invoke({\"question\": query})\n",
    "display(Markdown(response['generation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVAL FROM VECTOR DB---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---NO DOCS, BUT QUESTION SUGGESTS SQL---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: QUERY SQL DATABASE---\n",
      "---EXECUTE SQL QUERY OR METRIC COMPUTATION---\n",
      "Kết nối thành công đến PostgreSQL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trung\\AppData\\Local\\Temp\\ipykernel_14452\\3799809131.py:100: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lỗi thực thi SQL: Execution failed on sql 'SELECT *\n",
      "FROM stocks\n",
      "WHERE date BETWEEN '2024-01-01' AND '2024-12-31'\n",
      "AND company = 'apple';': column \"company\" does not exist\n",
      "LINE 4: AND company = 'apple';\n",
      "            ^\n",
      "\n",
      "---GENERATE ANSWER---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Không có dữ liệu về toàn bộ dữ liệu stock của Apple năm 2024 trong cơ sở dữ liệu được cung cấp."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Lấy toàn bộ dữ liệu stock của apple năm 2024 trong database\"\n",
    "response = agentic_rag.invoke({\"question\": query})\n",
    "display(Markdown(response['generation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVAL FROM VECTOR DB---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT NOT RELEVANT, SUGGEST WEB SEARCH---\n",
      "---GRADE: DOCUMENT NOT RELEVANT, SUGGEST WEB SEARCH---\n",
      "---GRADE: DOCUMENT NOT RELEVANT, SUGGEST WEB SEARCH---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: WEB SEARCH NEEDED, REWRITE QUERY---\n",
      "---REWRITE QUERY---\n",
      "---WEB SEARCH---\n",
      "DOCS TYPE: <class 'list'>\n",
      "FIRST ELEMENT TYPE: <class 'dict'>\n",
      "---GENERATE ANSWER---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Dựa trên các thông tin được cung cấp, không có dữ liệu cụ thể hoặc dự đoán rõ ràng về đội tuyển nào sẽ vô địch World Cup 2024. Tuy nhiên, có một số nhận định về các đội bóng mạnh hiện tại:\n",
       "\n",
       "- Tây Ban Nha được đánh giá rất cao với khả năng tấn công mạnh mẽ và phòng ngự chắc chắn, được dự đoán có cơ hội lớn vô địch EURO 2024 (60,38% theo siêu máy tính Opta) và được dự đoán sẽ thắng Anh trong trận chung kết EURO 2024.\n",
       "- Pháp là đương kim vô địch World Cup, sở hữu dàn cầu thủ tài năng và kinh nghiệm, với lối chơi tấn công đa dạng và khả năng kiểm soát trận đấu tốt.\n",
       "- Tuyển Anh cũng được đánh giá cao, có khả năng vô địch EURO 2024 với xác suất 19,9% theo hãng dữ liệu Opta.\n",
       "\n",
       "Tuy nhiên, các dự đoán này chủ yếu liên quan đến EURO 2024, không phải World Cup 2024. Vì vậy, không có thông tin cụ thể nào về đội tuyển có khả năng vô địch World Cup 2024 trong phần thông tin được cung cấp.\n",
       "\n",
       "**Tóm lại:** Không có dự đoán rõ ràng về đội vô địch World Cup 2024 trong dữ liệu hiện tại. Các đội tuyển như Tây Ban Nha, Pháp và Anh được xem là những ứng viên mạnh dựa trên phong độ và thành tích gần đây, nhưng chưa có dự đoán chính thức nào cho World Cup 2024."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Ai vô địch World Cup 2024?\"\n",
    "response = agentic_rag.invoke({\"question\": query})\n",
    "display(Markdown(response['generation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVAL FROM VECTOR DB---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT NOT RELEVANT, SUGGEST WEB SEARCH---\n",
      "---GRADE: DOCUMENT NOT RELEVANT, SUGGEST WEB SEARCH---\n",
      "---GRADE: DOCUMENT NOT RELEVANT, SUGGEST WEB SEARCH---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: WEB SEARCH NEEDED, REWRITE QUERY---\n",
      "---REWRITE QUERY---\n",
      "---WEB SEARCH---\n",
      "DOCS TYPE: <class 'list'>\n",
      "FIRST ELEMENT TYPE: <class 'dict'>\n",
      "---GENERATE ANSWER---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Đội vô địch World Cup gần đây nhất là đội tuyển Argentina. Trong giải vô địch bóng đá thế giới được tổ chức tại Qatar năm 2022, Argentina đã giành chiến thắng trước Pháp với tỷ số 4–2 trong loạt sút luân lưu sau khi hai đội hòa 3–3 sau hiệp phụ. Đây là lần thứ ba Argentina đoạt cúp vô địch World Cup."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"World Cup gần nhất là đội nào vô địch?\"\n",
    "response = agentic_rag.invoke({\"question\": query})\n",
    "display(Markdown(response['generation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVAL FROM VECTOR DB---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: WEB SEARCH NEEDED, REWRITE QUERY---\n",
      "---REWRITE QUERY---\n",
      "---WEB SEARCH---\n",
      "DOCS TYPE: <class 'list'>\n",
      "FIRST ELEMENT TYPE: <class 'dict'>\n",
      "---GENERATE ANSWER---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Thủ đô của Việt Nam hiện nay là thành phố Hà Nội. Hà Nội là trung tâm chính trị, hành chính quốc gia, nơi đặt trụ sở của các cơ quan trung ương của Đảng, Nhà nước và các tổ chức chính trị - xã hội, cũng như các cơ quan đại diện ngoại giao và tổ chức quốc tế. Đây cũng là trung tâm lớn về văn hóa, giáo dục, khoa học, công nghệ, kinh tế và giao dịch quốc tế của cả nước.\n",
       "\n",
       "Hà Nội có vị trí ở phía Tây Bắc của vùng đồng bằng châu thổ sông Hồng, với diện tích khoảng 3.359,82 km² và dân số khoảng 8,4 triệu người. Thành phố này đã được UNESCO trao danh hiệu \"Thành phố vì hòa bình\" vào năm 1999 và được Chủ tịch nước tặng danh hiệu \"Thủ đô anh hùng\" vào năm 2000. Hà Nội là thủ đô lâu đời nhất trong số 11 thủ đô của các quốc gia Đông Nam Á, với lịch sử hơn 1000 năm.\n",
       "\n",
       "Theo Hiến pháp năm 2013 của nước Cộng hòa xã hội chủ nghĩa Việt Nam, thủ đô chính thức của Việt Nam là Hà Nội."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Thủ đô Viêt Nam là gì?\"\n",
    "response = agentic_rag.invoke({\"question\": query})\n",
    "display(Markdown(response['generation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
